{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "import gtfparse\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember to review all paths in the Config section below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "project_dir = Path(\"/data/teamgdansk/mwaleron/carmen-analysis\")\n",
    "\n",
    "data_dir = project_dir.joinpath(\"data\")\n",
    "temp_dir = project_dir.joinpath(\"temp\")\n",
    "\n",
    "data_subs_dir = data_dir.joinpath(\"subsidiary-files\")\n",
    "data_pub_dir = data_dir.joinpath(\"to-be-published\")\n",
    "\n",
    "gencode_data_dir = data_subs_dir.joinpath(\"GENCODE\")\n",
    "gencodev39_raw_file = temp_dir.joinpath(\"gencode.v39.annotation.gtf\")\n",
    "gencodev39_stripped = gencode_data_dir.joinpath(\"gencode.v39.annotation.stripped.versions.parquet\")\n",
    "\n",
    "contig_scaffold_list_file = data_pub_dir.joinpath(\"scaff_all_expanded.tsv\")\n",
    "contig_peptide_list_file = data_pub_dir.joinpath(\"contig_unique_peptide_list.tsv\")\n",
    "\n",
    "exon_regions_file = data_subs_dir.joinpath(\"exon_regions.parquet\")\n",
    "gene_stats_file = data_subs_dir.joinpath(\"per_gene_stats.parquet\")\n",
    "exon_regions_per_bp_file = data_subs_dir.joinpath(\"per_bp_coverage.parquet\")\n",
    "\n",
    "exon_ranges_in_genecode_file = data_subs_dir.joinpath(\"exon_regions.parquet\")\n",
    "exon_ranges_in_contigs_file = data_subs_dir.joinpath(\"evenbiggerjoin_cause_its_exons_not_just_genes_v2_just_the_contig_genes.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the reference annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin the analysis we will need to obtain the reference human genome annotation as a GTF file, to replicate the results of this paper you should use the release 39, corresponding to Hg38.p13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# wget https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_39/gencode.v39.annotation.gtf.gz\n",
    "# mv gencode.v39.annotation.gtf.gz temp\n",
    "# cd temp\n",
    "# gunzip gencode.v39.annotation.gtf.gz\n",
    "# cd ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After obtaining the file we will transform it into a more immediately usable form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "gencodev39_tmp = gtfparse.parse_gtf_and_expand_attributes(gencodev39_raw_file)\\\n",
    "     .with_columns(\n",
    "     pl.col(\"gene_id\").str.replace(r\"\\.\\d*$\", \"\"),\n",
    "     pl.col(\"transcript_id\").str.replace(r\"\\.\\d*$\", \"\"),\n",
    "     pl.col(\"exon_id\").str.replace(r\"\\.\\d*$\", \"\"),\n",
    "     pl.col(\"protein_id\").str.replace(r\"\\.\\d*$\", \"\"),\n",
    " )\n",
    "gencodev39_tmp.write_parquet(gencodev39_stripped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gencodev39 = pl.read_parquet(gencodev39_stripped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis will now need to be sharded to reduce execute time, as such we will create some temporary directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list_file = temp_dir.joinpath(\"genes.tsv\")\n",
    "temp_dir.joinpath(\"stats\").mkdir(parents=True, exist_ok=True)\n",
    "temp_dir.joinpath(\"exons\").mkdir(parents=True, exist_ok=True)\n",
    "temp_dir.joinpath(\"nonexons\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to shard the calculation is to split it by unique gene id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.DataFrame(gencodev39[\"gene_id\"].unique()).write_csv(gene_list_file, separator=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the step where we parallelize the computation, you can use parallel, SLURM, or even run this sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and now you need to run the scripts per gene, have fun\n",
    "# cat genes.tsv | parallel --bar -j48 python calculate_coverage.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once done we collect the temporary result files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "genestats = pl.read_parquet(temp_dir.joinpath(\"stats/*\"))\n",
    "genestats.write_parquet(gene_stats_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exon_regions = pl.read_parquet(temp_dir.joinpath(\"exons/*\"))\n",
    "exon_regions.write_parquet(exon_regions_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can analyze which parts of the genes are covered by exonic sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "justgenes = gencodev39.filter(pl.col(\"feature\") == \"gene\")\n",
    "exon_regions = pl.read_parquet(exon_ranges_in_genecode_file)\n",
    "cooler_exon_regions = exon_regions.join(justgenes, on=\"gene_id\"\n",
    "                ).select(\"gene_id\", \"exon_ranges\", \"start\", \"seqname\",\n",
    "                pl.col(\"exon_ranges\").list.to_array(2).arr.get(0).alias(\"exon_start\") + pl.col(\"start\"),\n",
    "                pl.col(\"exon_ranges\").list.to_array(2).arr.get(1).alias(\"exon_end\") + pl.col(\"start\")\n",
    "                ).select(\n",
    "                    \"gene_id\", \"seqname\", \"exon_start\", \"exon_end\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = duckdb.sql('''\n",
    "    select *\n",
    "    from contig_scaffold_list c, cooler_exon_regions e\n",
    "    where (e.seqname = c.Chromosome)\n",
    "        and (\n",
    "                (c.Gene_start between e.exon_start and e.exon_end)\n",
    "            or  (c.Gene_end   between e.exon_start and e.exon_end)\n",
    "            or  (\n",
    "                    (c.Gene_start < e.exon_start)\n",
    "                and (c.Gene_end > e.exon_end)\n",
    "            )\n",
    "        )\n",
    "''')\n",
    "exon_join = res.pl()\n",
    "exon_join.write_parquet(exon_ranges_in_contigs_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to clean up and delete all additional files and directories created throughout the analysis.\n",
    "\n",
    "**Do not run the second cell unless you want to end your work here or start over.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a safety code\n",
    "\n",
    "raise KeyboardInterrupt(\"Are you sure you want to run the cell below?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to do a clean-up\n",
    "gene_list_file.unlink()\n",
    "temp_dir.joinpath(\"stats/*\").unlink()\n",
    "temp_dir.joinpath(\"stats\").rmdir()\n",
    "temp_dir.joinpath(\"exons/*\").unlink()\n",
    "temp_dir.joinpath(\"exons\").rmdir()\n",
    "temp_dir.joinpath(\"nonexons/*\").unlink()\n",
    "temp_dir.joinpath(\"nonexons\").rmdir()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carmen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
