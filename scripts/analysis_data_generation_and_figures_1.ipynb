{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import itertools\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import logomaker\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl  # ver=0.20, needs `pyarrow` and `xlsx2csv` packages\n",
    "import seaborn as sns\n",
    "import umap\n",
    "from Bio import motifs\n",
    "from Bio.Seq import Seq\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.transforms import ScaledTranslation\n",
    "from matplotlib_venn import venn2\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from natsort import natsorted\n",
    "from scipy.spatial import ConvexHull\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm.contrib import tzip\n",
    "from tqdm.notebook import tqdm  # needs `ipywidgets` package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember to review all paths in the Config section below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "\n",
    "# Main directories\n",
    "\n",
    "project_dir = Path(\"/data/teamgdansk/apalkowski/carmen-paper\")\n",
    "\n",
    "data_dir = project_dir.joinpath(\"data\")\n",
    "figures_dir = project_dir.joinpath(\"figures\")\n",
    "temp_dir = project_dir.joinpath(\"temp\")\n",
    "\n",
    "data_pub_dir = data_dir.joinpath(\"to-be-published\")\n",
    "\n",
    "data_subs_dir = data_dir.joinpath(\"subsidiary-files\")\n",
    "\n",
    "figures_gen_dir = figures_dir.joinpath(\"script-generated\")\n",
    "figures_main_dir = figures_gen_dir.joinpath(\"main-panels\")\n",
    "figures_supp_dir = figures_gen_dir.joinpath(\"supplementary\")\n",
    "\n",
    "data_pub_dir.mkdir(parents=True, exist_ok=True)\n",
    "data_subs_dir.mkdir(parents=True, exist_ok=True)\n",
    "figures_main_dir.mkdir(parents=True, exist_ok=True)\n",
    "figures_supp_dir.mkdir(parents=True, exist_ok=True)\n",
    "temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Core source files\n",
    "\n",
    "# Elements of the CARMEN database (might exist outside of this project directory)\n",
    "db_main_file = \"/data/teamgdansk/apalkowski/ashwins-database-development/data/final-db/neoantigen-db-main.tsv\"\n",
    "# db_main_file = data_dir.joinpath(\"neoantigen-db-main.tsv\")\n",
    "\n",
    "# Haplotype frequencies from NMDP Registry Haplotype Frequencies database\n",
    "freqs_dir = data_dir.joinpath(\"nmdp-hla-frequencies\")\n",
    "# freqs_pop_desc_file = f\"{data_dir}/{freqs_dir}/populations-description.csv\"\n",
    "freqs_pop_desc_file = freqs_dir.joinpath(\"populations-description.csv\")\n",
    "freqs_pop_desc_col_pop_code = \"Population_code\"  # column name\n",
    "freqs_pop_desc_col_desc = \"Description\"  # column name\n",
    "freqs_pop_desc_col_a_b_drb1 = \"A_B_DRB1_count\"  # column name\n",
    "freqs_pop_desc_col_c = \"C_count\"  # column name\n",
    "freqs_pop_codes = pl.read_csv(freqs_pop_desc_file)[\n",
    "    freqs_pop_desc_col_pop_code\n",
    "].to_list()\n",
    "# The following files are available from the database website (https://frequency.nmdp.org)\n",
    "# freqs_a_org_file = f\"{data_dir}/{freqs_dir}/A.xlsx\"\n",
    "# freqs_b_org_file = f\"{data_dir}/{freqs_dir}/B.xlsx\"\n",
    "# freqs_c_org_file = f\"{data_dir}/{freqs_dir}/C.xlsx\"\n",
    "# freqs_abc_org_file = f\"{data_dir}/{freqs_dir}/A~C~B.xlsx\"\n",
    "freqs_a_org_file = freqs_dir.joinpath(\"A.xlsx\")\n",
    "freqs_b_org_file = freqs_dir.joinpath(\"B.xlsx\")\n",
    "freqs_c_org_file = freqs_dir.joinpath(\"C.xlsx\")\n",
    "freqs_abc_org_file = freqs_dir.joinpath(\"A~C~B.xlsx\")\n",
    "freqs_col_a = \"A\"  # column name\n",
    "freqs_col_b = \"B\"  # column name\n",
    "freqs_col_c = \"C\"  # column name\n",
    "freqs_org_cols_freqs = [f\"{c}_freq\" for c in freqs_pop_codes]  # column names\n",
    "\n",
    "# MHC Motif Atlas peptides, available from the project website (http://mhcmotifatlas.org)\n",
    "# motif_atlas_peps_src_file = f\"{data_dir}/data_classI_all_peptides.txt\"\n",
    "motif_atlas_peps_src_file = data_dir.joinpath(\"data_classI_all_peptides.txt\")\n",
    "motif_atlas_peps_col_allele = \"Allele\"  # column name\n",
    "motif_atlas_peps_col_peptide = \"Peptide\"  # column name\n",
    "\n",
    "# Files produced outside of this notebook\n",
    "\n",
    "# main_samples_file = f\"{data_dir}/main-output-table-1.tsv\"\n",
    "# main_samples_file_2 = f\"{data_dir}/main-output-table-2.tsv\"\n",
    "main_samples_file = data_dir.joinpath(\"main-output-table-1.tsv\")\n",
    "main_samples_file_2 = data_dir.joinpath(\"main-output-table-2.tsv\")\n",
    "main_samples_col_sample_name = \"Sample\"  # column name\n",
    "main_samples_col_peptides = \"Peptides\"  # column name\n",
    "main_samples_col_binding_alleles = \"Binding_alleles\"  # column name\n",
    "main_samples_col_umap_x = \"x\"  # column name\n",
    "main_samples_col_umap_y = \"y\"  # column name\n",
    "main_samples_col_label = \"label\"  # column name\n",
    "main_samples_list_sep = \",\"\n",
    "\n",
    "# main_motif_atlas_emb_file = f\"{data_dir}/main-embeddings_MHCMotifA_pssms.tsv\"\n",
    "main_motif_atlas_emb_file = data_dir.joinpath(\"main-embeddings_MHCMotifA_pssms.tsv\")\n",
    "main_motif_atlas_emb_col_x = \"0\"  # column name\n",
    "main_motif_atlas_emb_col_y = \"1\"  # column name\n",
    "\n",
    "# ml_roc_curve_1_1_hla_file = f\"{data_dir}/1_1_HLA_coordinates.csv\"\n",
    "# ml_roc_curve_1_1_no_hla_file = f\"{data_dir}/1_1_no_HLA_coordinates.csv\"\n",
    "# ml_roc_curve_1_5_hla_file = f\"{data_dir}/1_5_HLA_coordinates.csv\"\n",
    "# ml_roc_curve_1_5_no_hla_file = f\"{data_dir}/1_5_no_HLA_coordinates.csv\"\n",
    "ml_roc_curve_1_1_hla_file = data_dir.joinpath(\"1_1_HLA_coordinates.csv\")\n",
    "ml_roc_curve_1_1_no_hla_file = data_dir.joinpath(\"1_1_no_HLA_coordinates.csv\")\n",
    "ml_roc_curve_1_5_hla_file = data_dir.joinpath(\"1_5_HLA_coordinates.csv\")\n",
    "ml_roc_curve_1_5_no_hla_file = data_dir.joinpath(\"1_5_no_HLA_coordinates.csv\")\n",
    "ml_roc_curve_col_x = \"x\"  # column name\n",
    "ml_roc_curve_col_y = \"y\"  # column name\n",
    "\n",
    "# External database files\n",
    "ext_data_files = [\n",
    "    freqs_a_org_file,\n",
    "    freqs_b_org_file,\n",
    "    freqs_c_org_file,\n",
    "    freqs_abc_org_file,\n",
    "    motif_atlas_peps_src_file,\n",
    "]\n",
    "\n",
    "# Generated data files\n",
    "\n",
    "# Files to be published\n",
    "\n",
    "samples_pub_file = data_pub_dir.joinpath(\n",
    "    \"carmen-peptide-clusters-characteristics.parquet\"\n",
    ")\n",
    "samples_pub_col_id = \"ID\"  # column name\n",
    "\n",
    "samples_pub_pssms_file = data_pub_dir.joinpath(\"carmen-peptide-clusters-pssms.json\")\n",
    "\n",
    "# Subsidiary files\n",
    "\n",
    "# Summarized characteristics of samples\n",
    "# samples_main_file = f\"{data_subs_dir}/samples-main.csv\"\n",
    "# samples_supp_file = f\"{data_subs_dir}/samples-supp.csv\"\n",
    "samples_main_file = data_subs_dir.joinpath(\"samples-main.csv\")\n",
    "samples_supp_file = data_subs_dir.joinpath(\"samples-supp.csv\")\n",
    "samples_col_sample_name = \"Sample_name\"  # column name\n",
    "samples_col_peptides = \"Peptides\"  # column name\n",
    "samples_col_binding_alleles = \"Binding_alleles\"  # column name\n",
    "samples_col_umap_x = \"UMAP_x\"  # column name\n",
    "samples_col_umap_y = \"UMAP_y\"  # column name\n",
    "samples_col_label = \"Label\"  # column name\n",
    "samples_col_peptides_9 = \"Peptides_9\"  # column name\n",
    "samples_col_binding_alleles_clean = \"Binding_alleles_clean\"  # column name\n",
    "samples_cols_freqs_a = [f\"Freq_{c}_A\" for c in freqs_pop_codes]  # column names\n",
    "samples_cols_freqs_b = [f\"Freq_{c}_B\" for c in freqs_pop_codes]  # column names\n",
    "samples_cols_freqs_c = [f\"Freq_{c}_C\" for c in freqs_pop_codes]  # column names\n",
    "samples_cols_freqs_abc_any = [\n",
    "    f\"Freq_{c}_ABC_any\" for c in freqs_pop_codes\n",
    "]  # column names\n",
    "samples_cols_freqs_abc_all = [\n",
    "    f\"Freq_{c}_ABC_all\" for c in freqs_pop_codes\n",
    "]  # column names\n",
    "samples_list_sep = \";\"\n",
    "samples_list_cols = [\n",
    "    samples_col_peptides,\n",
    "    samples_col_binding_alleles,\n",
    "    samples_col_peptides_9,\n",
    "    samples_col_binding_alleles_clean,\n",
    "]\n",
    "\n",
    "# UMAP model for the supplementary dataset\n",
    "# umap_reducer_supp_file = f\"{data_subs_dir}/umap-reducer-supp.pkl\"\n",
    "umap_reducer_supp_file = data_subs_dir.joinpath(\"umap-reducer-supp.pickle\")\n",
    "\n",
    "# Modified populations haplotype frequencies files\n",
    "# freqs_a_file = f\"{data_subs_dir}/pop-freqs-a.csv\"\n",
    "# freqs_b_file = f\"{data_subs_dir}/pop-freqs-b.csv\"\n",
    "# freqs_c_file = f\"{data_subs_dir}/pop-freqs-c.csv\"\n",
    "# freqs_abc_file = f\"{data_subs_dir}/pop-freqs-abc.csv\"\n",
    "freqs_a_file = data_subs_dir.joinpath(\"pop-freqs-a.csv\")\n",
    "freqs_b_file = data_subs_dir.joinpath(\"pop-freqs-b.csv\")\n",
    "freqs_c_file = data_subs_dir.joinpath(\"pop-freqs-c.csv\")\n",
    "freqs_abc_file = data_subs_dir.joinpath(\"pop-freqs-abc.csv\")\n",
    "freqs_cols_freqs = [f\"Freq_{c}\" for c in freqs_pop_codes]  # column names\n",
    "\n",
    "# Modified MHC Motif Atlas peptides\n",
    "# motif_atlas_peps_file = f\"{data_subs_dir}/motif-atlas-peptides.csv\"\n",
    "# supp_motif_atlas_emb_file = f\"{data_subs_dir}/motif-atlas-supp-umap-emb.csv\"\n",
    "motif_atlas_peps_file = data_subs_dir.joinpath(\"motif-atlas-peptides.csv\")\n",
    "supp_motif_atlas_emb_file = data_subs_dir.joinpath(\"motif-atlas-supp-umap-emb.csv\")\n",
    "supp_motif_atlas_emb_col_allele = \"Allele\"  # column name\n",
    "supp_motif_atlas_emb_col_x = \"UMAP_x\"  # column name\n",
    "supp_motif_atlas_emb_col_y = \"UMAP_y\"  # column name\n",
    "\n",
    "\n",
    "# Amino acids combinations in peptides\n",
    "# aa_combinations_file = lambda n_pos: f\"{data_subs_dir}/aa-combinations-9aa-{n_pos}.csv\"\n",
    "def aa_combinations_file(n_pos):\n",
    "    return data_subs_dir.joinpath(f\"aa-combinations-9aa-{n_pos}.csv\")\n",
    "\n",
    "\n",
    "aa_combinations_col_pos = \"Positions\"  # column name\n",
    "aa_combinations_col_aa = \"Amino_acids\"  # column name\n",
    "aa_combinations_col_pep = \"Peptides\"  # column name\n",
    "aa_combinations_list_sep = \";\"\n",
    "\n",
    "# Other\n",
    "\n",
    "peptide_len = 9\n",
    "\n",
    "AMINO_ACIDS = [\n",
    "    \"A\",\n",
    "    \"R\",\n",
    "    \"N\",\n",
    "    \"D\",\n",
    "    \"C\",\n",
    "    \"Q\",\n",
    "    \"E\",\n",
    "    \"G\",\n",
    "    \"H\",\n",
    "    \"I\",\n",
    "    \"L\",\n",
    "    \"K\",\n",
    "    \"M\",\n",
    "    \"F\",\n",
    "    \"P\",\n",
    "    \"S\",\n",
    "    \"T\",\n",
    "    \"W\",\n",
    "    \"Y\",\n",
    "    \"V\",\n",
    "]\n",
    "\n",
    "# Matplotlib config\n",
    "plt.rcdefaults()\n",
    "\n",
    "main_font_size = 7  # Minimum text size: 5 pt.\n",
    "label_font_size = 10\n",
    "\n",
    "max_fig_width_double_col = 180  # mm (Nature standards)\n",
    "max_fig_width_single_col = 89  # mm\n",
    "# Figures can also be 120 mm in width where necessary.\n",
    "# Page height is 279 mm. Content size is about 250/245/243 mm?\n",
    "max_fig_height = 210  # mm\n",
    "max_max_fig_height = 243  # mm\n",
    "\n",
    "default_point_size = 15\n",
    "\n",
    "axis_color = \"0.15\"\n",
    "\n",
    "label_kwargs = dict(\n",
    "    ha=\"right\", va=\"center\", fontsize=label_font_size, weight=\"bold\", color=\"black\"\n",
    ")\n",
    "\n",
    "plt.rcParams[\"text.color\"] = axis_color\n",
    "plt.rcParams[\"axes.labelcolor\"] = axis_color\n",
    "plt.rcParams[\"xtick.color\"] = axis_color\n",
    "plt.rcParams[\"ytick.color\"] = axis_color\n",
    "plt.rcParams[\"axes.edgecolor\"] = axis_color\n",
    "\n",
    "plt.rcParams[\"font.size\"] = main_font_size\n",
    "plt.rcParams[\"axes.labelsize\"] = main_font_size\n",
    "plt.rcParams[\"axes.titlesize\"] = main_font_size\n",
    "plt.rcParams[\"xtick.labelsize\"] = main_font_size\n",
    "plt.rcParams[\"ytick.labelsize\"] = main_font_size\n",
    "plt.rcParams[\"legend.fontsize\"] = main_font_size\n",
    "plt.rcParams[\"figure.labelsize\"] = main_font_size\n",
    "plt.rcParams[\"figure.titlesize\"] = main_font_size\n",
    "\n",
    "plt.rcParams[\"axes.spines.top\"] = False\n",
    "plt.rcParams[\"axes.spines.right\"] = False\n",
    "\n",
    "plt.rcParams[\"savefig.transparent\"] = True\n",
    "\n",
    "# Not sure about these ones, need to test\n",
    "plt.rcParams[\"pdf.fonttype\"] = 42\n",
    "plt.rcParams[\"ps.fonttype\"] = 42\n",
    "plt.rcParams[\"svg.fonttype\"] = \"none\"\n",
    "\n",
    "# This is useful but may cause problems with Seaborn package\n",
    "# plt.rcParams[\"figure.constrained_layout.use\"] = True\n",
    "\n",
    "# Setting random seed\n",
    "random_seed = 42\n",
    "\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "\n",
    "\n",
    "def figsize_in_mm(width, height):\n",
    "    mm = 1 / 25.4  # millimeters in inches\n",
    "    return (width * mm, height * mm)\n",
    "\n",
    "\n",
    "def color_pallet(colors_n):\n",
    "    if colors_n <= 20:\n",
    "        colors = [plt.cm.tab20(i) for i in range(colors_n)]\n",
    "    else:\n",
    "        colors = [plt.cm.tab20(i) for i in range(20)]\n",
    "        remaining_c_n = colors_n - 20\n",
    "        if remaining_c_n <= 12:\n",
    "            colors += [plt.cm.Set3(i) for i in range(remaining_c_n)]\n",
    "        else:\n",
    "            colors += [plt.cm.Set3(i) for i in range(12)]\n",
    "            remaining_c_n -= 12\n",
    "            if remaining_c_n <= 9:\n",
    "                colors += [plt.cm.Pastel1(i) for i in range(remaining_c_n)]\n",
    "            else:\n",
    "                colors += [plt.cm.Pastel1(i) for i in range(9)]\n",
    "                remaining_c_n -= 9\n",
    "                colors_last = [\n",
    "                    plt.cm.nipy_spectral(i)\n",
    "                    for i in np.linspace(0.05, 1.0, remaining_c_n)\n",
    "                ]\n",
    "                random.shuffle(colors_last)\n",
    "                colors += colors_last\n",
    "    return colors\n",
    "\n",
    "\n",
    "def calculate_centroid(coordinates):\n",
    "    sum_x = sum(point[0] for point in coordinates)\n",
    "    sum_y = sum(point[1] for point in coordinates)\n",
    "    n = len(coordinates)\n",
    "    centroid = (sum_x / n, sum_y / n)\n",
    "    return centroid\n",
    "\n",
    "\n",
    "def hobohm(peptides, threshold=0.63):\n",
    "    peps_n = len(peptides)\n",
    "    # seq_len = len(peptides[0])\n",
    "    seq_len = 9\n",
    "\n",
    "    aa_mat = np.array([list(p) for p in peptides])\n",
    "\n",
    "    dist_mat = np.zeros((peps_n, peps_n))\n",
    "    for i in range(peps_n - 1):\n",
    "        d = 1 - np.sum(aa_mat[i] == aa_mat[i + 1 :], 1) / seq_len\n",
    "        dist_mat[i, i + 1 :] = d\n",
    "        dist_mat[i + 1 :, i] = d\n",
    "\n",
    "    clusters = []\n",
    "    not_assigned = np.full(peps_n, True)\n",
    "    for i in range(peps_n):\n",
    "        if not_assigned[i]:\n",
    "            c = [i]\n",
    "            ok_peps = dist_mat[i, i + 1 :] < (1 - threshold)\n",
    "            c_a = np.nonzero(ok_peps & not_assigned[i + 1 :])[0] + 1 + i\n",
    "            c += list(c_a)\n",
    "            clusters.append(c)\n",
    "            if c_a.shape[0] > 0:\n",
    "                not_assigned[c_a] = False\n",
    "\n",
    "    weights = np.zeros(peps_n)\n",
    "    for c in clusters:\n",
    "        c_len = len(c)\n",
    "        for i in c:\n",
    "            weights[i] = 1 / c_len\n",
    "\n",
    "    alpha = np.full(seq_len, len(clusters) - 1)\n",
    "\n",
    "    return alpha, weights\n",
    "\n",
    "\n",
    "blosum62_matrix = {\n",
    "    \"A\": [\n",
    "        0.2901,\n",
    "        0.0446,\n",
    "        0.0427,\n",
    "        0.041,\n",
    "        0.065,\n",
    "        0.0559,\n",
    "        0.0552,\n",
    "        0.0783,\n",
    "        0.042,\n",
    "        0.0471,\n",
    "        0.0445,\n",
    "        0.057,\n",
    "        0.0522,\n",
    "        0.0338,\n",
    "        0.0568,\n",
    "        0.1099,\n",
    "        0.073,\n",
    "        0.0303,\n",
    "        0.0405,\n",
    "        0.07,\n",
    "    ],\n",
    "    \"R\": [\n",
    "        0.031,\n",
    "        0.345,\n",
    "        0.0449,\n",
    "        0.0299,\n",
    "        0.0163,\n",
    "        0.0735,\n",
    "        0.0497,\n",
    "        0.0229,\n",
    "        0.0458,\n",
    "        0.0177,\n",
    "        0.0243,\n",
    "        0.1071,\n",
    "        0.0321,\n",
    "        0.019,\n",
    "        0.0258,\n",
    "        0.0401,\n",
    "        0.0355,\n",
    "        0.0227,\n",
    "        0.028,\n",
    "        0.0219,\n",
    "    ],\n",
    "    \"N\": [\n",
    "        0.0256,\n",
    "        0.0388,\n",
    "        0.3169,\n",
    "        0.069,\n",
    "        0.0163,\n",
    "        0.0441,\n",
    "        0.0405,\n",
    "        0.0391,\n",
    "        0.0534,\n",
    "        0.0147,\n",
    "        0.0142,\n",
    "        0.0415,\n",
    "        0.0201,\n",
    "        0.0169,\n",
    "        0.0233,\n",
    "        0.0541,\n",
    "        0.0434,\n",
    "        0.0152,\n",
    "        0.0218,\n",
    "        0.0165,\n",
    "    ],\n",
    "    \"D\": [\n",
    "        0.0297,\n",
    "        0.031,\n",
    "        0.0831,\n",
    "        0.3974,\n",
    "        0.0163,\n",
    "        0.0471,\n",
    "        0.0902,\n",
    "        0.0337,\n",
    "        0.0382,\n",
    "        0.0177,\n",
    "        0.0152,\n",
    "        0.0415,\n",
    "        0.0201,\n",
    "        0.0169,\n",
    "        0.031,\n",
    "        0.0489,\n",
    "        0.0375,\n",
    "        0.0152,\n",
    "        0.0187,\n",
    "        0.0178,\n",
    "    ],\n",
    "    \"C\": [\n",
    "        0.0216,\n",
    "        0.0078,\n",
    "        0.009,\n",
    "        0.0075,\n",
    "        0.4837,\n",
    "        0.0088,\n",
    "        0.0074,\n",
    "        0.0108,\n",
    "        0.0076,\n",
    "        0.0162,\n",
    "        0.0162,\n",
    "        0.0086,\n",
    "        0.0161,\n",
    "        0.0106,\n",
    "        0.0103,\n",
    "        0.0175,\n",
    "        0.0178,\n",
    "        0.0076,\n",
    "        0.0093,\n",
    "        0.0192,\n",
    "    ],\n",
    "    \"Q\": [\n",
    "        0.0256,\n",
    "        0.0484,\n",
    "        0.0337,\n",
    "        0.0299,\n",
    "        0.0122,\n",
    "        0.2147,\n",
    "        0.0645,\n",
    "        0.0189,\n",
    "        0.0382,\n",
    "        0.0133,\n",
    "        0.0162,\n",
    "        0.0535,\n",
    "        0.0281,\n",
    "        0.0106,\n",
    "        0.0207,\n",
    "        0.0332,\n",
    "        0.0276,\n",
    "        0.0152,\n",
    "        0.0218,\n",
    "        0.0165,\n",
    "    ],\n",
    "    \"E\": [\n",
    "        0.0405,\n",
    "        0.0523,\n",
    "        0.0494,\n",
    "        0.0914,\n",
    "        0.0163,\n",
    "        0.1029,\n",
    "        0.2965,\n",
    "        0.0256,\n",
    "        0.0534,\n",
    "        0.0177,\n",
    "        0.0202,\n",
    "        0.0708,\n",
    "        0.0281,\n",
    "        0.019,\n",
    "        0.0362,\n",
    "        0.0524,\n",
    "        0.0394,\n",
    "        0.0227,\n",
    "        0.028,\n",
    "        0.0233,\n",
    "    ],\n",
    "    \"G\": [\n",
    "        0.0783,\n",
    "        0.0329,\n",
    "        0.0652,\n",
    "        0.0466,\n",
    "        0.0325,\n",
    "        0.0412,\n",
    "        0.035,\n",
    "        0.5101,\n",
    "        0.0382,\n",
    "        0.0206,\n",
    "        0.0213,\n",
    "        0.0432,\n",
    "        0.0281,\n",
    "        0.0254,\n",
    "        0.0362,\n",
    "        0.0663,\n",
    "        0.0434,\n",
    "        0.0303,\n",
    "        0.0249,\n",
    "        0.0247,\n",
    "    ],\n",
    "    \"H\": [\n",
    "        0.0148,\n",
    "        0.0233,\n",
    "        0.0315,\n",
    "        0.0187,\n",
    "        0.0081,\n",
    "        0.0294,\n",
    "        0.0258,\n",
    "        0.0135,\n",
    "        0.355,\n",
    "        0.0088,\n",
    "        0.0101,\n",
    "        0.0207,\n",
    "        0.0161,\n",
    "        0.0169,\n",
    "        0.0129,\n",
    "        0.0192,\n",
    "        0.0138,\n",
    "        0.0152,\n",
    "        0.0467,\n",
    "        0.0082,\n",
    "    ],\n",
    "    \"I\": [\n",
    "        0.0432,\n",
    "        0.0233,\n",
    "        0.0225,\n",
    "        0.0224,\n",
    "        0.0447,\n",
    "        0.0265,\n",
    "        0.0221,\n",
    "        0.0189,\n",
    "        0.0229,\n",
    "        0.271,\n",
    "        0.1154,\n",
    "        0.0276,\n",
    "        0.1004,\n",
    "        0.0634,\n",
    "        0.0258,\n",
    "        0.0297,\n",
    "        0.0533,\n",
    "        0.0303,\n",
    "        0.0436,\n",
    "        0.1646,\n",
    "    ],\n",
    "    \"L\": [\n",
    "        0.0594,\n",
    "        0.0465,\n",
    "        0.0315,\n",
    "        0.028,\n",
    "        0.065,\n",
    "        0.0471,\n",
    "        0.0368,\n",
    "        0.0283,\n",
    "        0.0382,\n",
    "        0.1679,\n",
    "        0.3755,\n",
    "        0.0432,\n",
    "        0.1968,\n",
    "        0.1142,\n",
    "        0.0362,\n",
    "        0.0419,\n",
    "        0.0651,\n",
    "        0.053,\n",
    "        0.0685,\n",
    "        0.1303,\n",
    "    ],\n",
    "    \"K\": [\n",
    "        0.0445,\n",
    "        0.1202,\n",
    "        0.0539,\n",
    "        0.0448,\n",
    "        0.0203,\n",
    "        0.0912,\n",
    "        0.0755,\n",
    "        0.0337,\n",
    "        0.0458,\n",
    "        0.0236,\n",
    "        0.0253,\n",
    "        0.2781,\n",
    "        0.0361,\n",
    "        0.019,\n",
    "        0.0413,\n",
    "        0.0541,\n",
    "        0.0454,\n",
    "        0.0227,\n",
    "        0.0312,\n",
    "        0.0261,\n",
    "    ],\n",
    "    \"M\": [\n",
    "        0.0175,\n",
    "        0.0155,\n",
    "        0.0112,\n",
    "        0.0093,\n",
    "        0.0163,\n",
    "        0.0206,\n",
    "        0.0129,\n",
    "        0.0094,\n",
    "        0.0153,\n",
    "        0.0368,\n",
    "        0.0496,\n",
    "        0.0155,\n",
    "        0.1606,\n",
    "        0.0254,\n",
    "        0.0103,\n",
    "        0.0157,\n",
    "        0.0197,\n",
    "        0.0152,\n",
    "        0.0187,\n",
    "        0.0316,\n",
    "    ],\n",
    "    \"F\": [\n",
    "        0.0216,\n",
    "        0.0174,\n",
    "        0.018,\n",
    "        0.0149,\n",
    "        0.0203,\n",
    "        0.0147,\n",
    "        0.0166,\n",
    "        0.0162,\n",
    "        0.0305,\n",
    "        0.0442,\n",
    "        0.0547,\n",
    "        0.0155,\n",
    "        0.0482,\n",
    "        0.3869,\n",
    "        0.0129,\n",
    "        0.0209,\n",
    "        0.0237,\n",
    "        0.0606,\n",
    "        0.1308,\n",
    "        0.0357,\n",
    "    ],\n",
    "    \"P\": [\n",
    "        0.0297,\n",
    "        0.0194,\n",
    "        0.0202,\n",
    "        0.0224,\n",
    "        0.0163,\n",
    "        0.0235,\n",
    "        0.0258,\n",
    "        0.0189,\n",
    "        0.0191,\n",
    "        0.0147,\n",
    "        0.0142,\n",
    "        0.0276,\n",
    "        0.0161,\n",
    "        0.0106,\n",
    "        0.4935,\n",
    "        0.0297,\n",
    "        0.0276,\n",
    "        0.0076,\n",
    "        0.0156,\n",
    "        0.0165,\n",
    "    ],\n",
    "    \"S\": [\n",
    "        0.085,\n",
    "        0.0446,\n",
    "        0.0697,\n",
    "        0.0522,\n",
    "        0.0407,\n",
    "        0.0559,\n",
    "        0.0552,\n",
    "        0.0513,\n",
    "        0.042,\n",
    "        0.025,\n",
    "        0.0243,\n",
    "        0.0535,\n",
    "        0.0361,\n",
    "        0.0254,\n",
    "        0.0439,\n",
    "        0.2199,\n",
    "        0.0927,\n",
    "        0.0227,\n",
    "        0.0312,\n",
    "        0.0329,\n",
    "    ],\n",
    "    \"T\": [\n",
    "        0.0499,\n",
    "        0.0349,\n",
    "        0.0494,\n",
    "        0.0354,\n",
    "        0.0366,\n",
    "        0.0412,\n",
    "        0.0368,\n",
    "        0.0297,\n",
    "        0.0267,\n",
    "        0.0398,\n",
    "        0.0334,\n",
    "        0.0397,\n",
    "        0.0402,\n",
    "        0.0254,\n",
    "        0.0362,\n",
    "        0.082,\n",
    "        0.2465,\n",
    "        0.0227,\n",
    "        0.028,\n",
    "        0.0494,\n",
    "    ],\n",
    "    \"W\": [\n",
    "        0.0054,\n",
    "        0.0058,\n",
    "        0.0045,\n",
    "        0.0037,\n",
    "        0.0041,\n",
    "        0.0059,\n",
    "        0.0055,\n",
    "        0.0054,\n",
    "        0.0076,\n",
    "        0.0059,\n",
    "        0.0071,\n",
    "        0.0052,\n",
    "        0.008,\n",
    "        0.0169,\n",
    "        0.0026,\n",
    "        0.0052,\n",
    "        0.0059,\n",
    "        0.4924,\n",
    "        0.028,\n",
    "        0.0055,\n",
    "    ],\n",
    "    \"Y\": [\n",
    "        0.0175,\n",
    "        0.0174,\n",
    "        0.0157,\n",
    "        0.0112,\n",
    "        0.0122,\n",
    "        0.0206,\n",
    "        0.0166,\n",
    "        0.0108,\n",
    "        0.0573,\n",
    "        0.0206,\n",
    "        0.0223,\n",
    "        0.0173,\n",
    "        0.0241,\n",
    "        0.0888,\n",
    "        0.0129,\n",
    "        0.0175,\n",
    "        0.0178,\n",
    "        0.0682,\n",
    "        0.3178,\n",
    "        0.0206,\n",
    "    ],\n",
    "    \"V\": [\n",
    "        0.0688,\n",
    "        0.031,\n",
    "        0.027,\n",
    "        0.0243,\n",
    "        0.0569,\n",
    "        0.0353,\n",
    "        0.0313,\n",
    "        0.0243,\n",
    "        0.0229,\n",
    "        0.1767,\n",
    "        0.0962,\n",
    "        0.0328,\n",
    "        0.0924,\n",
    "        0.055,\n",
    "        0.031,\n",
    "        0.0419,\n",
    "        0.071,\n",
    "        0.0303,\n",
    "        0.0467,\n",
    "        0.2689,\n",
    "    ],\n",
    "}\n",
    "blosum62_matrix = pd.DataFrame(blosum62_matrix).to_numpy()\n",
    "background = {\n",
    "    \"A\": 0.0755236,\n",
    "    \"R\": 0.0515842,\n",
    "    \"N\": 0.0453131,\n",
    "    \"D\": 0.0530344,\n",
    "    \"C\": 0.0169811,\n",
    "    \"Q\": 0.0402483,\n",
    "    \"E\": 0.0632002,\n",
    "    \"G\": 0.0684442,\n",
    "    \"H\": 0.0224067,\n",
    "    \"I\": 0.0573156,\n",
    "    \"L\": 0.0934327,\n",
    "    \"K\": 0.0594192,\n",
    "    \"M\": 0.0235696,\n",
    "    \"F\": 0.0407819,\n",
    "    \"P\": 0.0492775,\n",
    "    \"S\": 0.0722465,\n",
    "    \"T\": 0.0574747,\n",
    "    \"W\": 0.0125173,\n",
    "    \"Y\": 0.0319968,\n",
    "    \"V\": 0.0652477,\n",
    "}\n",
    "background = pd.DataFrame(pd.Series(background)).T.to_numpy()\n",
    "\n",
    "\n",
    "def strange_pssm(peptides, halfbits=False, hobohm_cluster=False, kl_logo=False):\n",
    "    peps_n = len(peptides)\n",
    "    # seq_len = len(peptides[0])\n",
    "    seq_len = 9\n",
    "\n",
    "    # Hobohm algorithm 1 sequence weighting\n",
    "    if hobohm_cluster:\n",
    "        alpha, weights = hobohm(peptides)\n",
    "        alpha = alpha.reshape(-1, 1)\n",
    "    else:\n",
    "        alpha = peps_n - 1\n",
    "        alpha = np.full((seq_len, 1), alpha)\n",
    "        weights = np.ones(peps_n)\n",
    "    weights = weights.reshape(-1, 1)\n",
    "\n",
    "    beta = 200\n",
    "\n",
    "    # peps = [Seq(p) for p in peptides]\n",
    "    # m = motifs.create(peps, alphabet=AMINO_ACIDS)\n",
    "    # # w_obs = pd.DataFrame(m.counts) / peps_n\n",
    "    # w_obs = pd.DataFrame(m.pwm)\n",
    "    # aa = w_obs.columns.to_list()\n",
    "    # w_obs = w_obs.to_numpy()\n",
    "    aa_mat = np.hsplit(np.array([list(p) for p in peptides]), seq_len)\n",
    "    w_obs = []\n",
    "    for i in range(seq_len):\n",
    "        aa_w = np.sum((AMINO_ACIDS == aa_mat[i]) * weights, axis=0)\n",
    "        w_obs.append(aa_w)\n",
    "    w_obs /= np.sum(w_obs, 1).reshape(-1, 1)\n",
    "\n",
    "    p_c = np.dot(w_obs, blosum62_matrix)\n",
    "    probs = (alpha * w_obs + beta * p_c) / (alpha + beta)  # self.p\n",
    "    p_not_0 = probs > 0\n",
    "    g_ref = np.ones(probs.shape) * background\n",
    "    if np.any(g_ref == 0):\n",
    "        for i in np.nonzero(g_ref == 0)[0]:\n",
    "            g_ref[i, :] = 1 / probs.shape[1]\n",
    "\n",
    "    pssm = np.zeros(probs.shape)  # self.w\n",
    "    pssm[probs == 0] = -99.999\n",
    "    if halfbits:\n",
    "        pssm[p_not_0] = np.log2(probs[p_not_0] / g_ref[p_not_0]) * 2\n",
    "        if np.any(pssm < -99.999):\n",
    "            pssm[pssm < -99.999] = -99.999\n",
    "    else:\n",
    "        pssm[p_not_0] = np.log2(probs[p_not_0] / g_ref[p_not_0])\n",
    "        if np.any(pssm < -50):\n",
    "            pssm[pssm < -50] = -50\n",
    "\n",
    "    # Kullback-Leibler logo\n",
    "    if kl_logo:\n",
    "        pssm = np.sum(pssm * probs, axis=1).reshape(-1, 1) * probs * np.sign(pssm)\n",
    "\n",
    "    return pd.DataFrame(pssm, columns=AMINO_ACIDS)\n",
    "\n",
    "\n",
    "def info_pssm(peptides, alphabet=AMINO_ACIDS):\n",
    "    peps = [Seq(p) for p in peptides]\n",
    "    m = motifs.create(peps, alphabet=alphabet)\n",
    "    m = pd.DataFrame(m.pwm)\n",
    "    m = logomaker.transform_matrix(\n",
    "        m, from_type=\"probability\", to_type=\"information\", pseudocount=0.0\n",
    "    )\n",
    "    return m\n",
    "\n",
    "\n",
    "def motif_logo(\n",
    "    peptides, ax=None, strange_logo=False, kl_logo=False, alphabet=AMINO_ACIDS\n",
    "):\n",
    "    if kl_logo or strange_logo:\n",
    "        m = strange_pssm(peptides, halfbits=False, hobohm_cluster=True, kl_logo=kl_logo)\n",
    "    else:\n",
    "        m = info_pssm(peptides, alphabet=alphabet)\n",
    "\n",
    "    m.index = [i + 1 for i in range(m.shape[0])]\n",
    "\n",
    "    if kl_logo or strange_logo:\n",
    "        baseline_width = 1.5\n",
    "    else:\n",
    "        baseline_width = 0.0\n",
    "\n",
    "    logo = logomaker.Logo(\n",
    "        m,\n",
    "        color_scheme=\"weblogo_protein\",\n",
    "        stack_order=\"big_on_top\",\n",
    "        flip_below=False,\n",
    "        center_values=False,\n",
    "        baseline_width=baseline_width,\n",
    "        vpad=0.05,\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    return logo\n",
    "\n",
    "\n",
    "def cos_sim_clustermap_order(df):\n",
    "    # Calculate cosine similarity for the populations\n",
    "    cos_sim = cosine_similarity(df.transpose())\n",
    "    cos_sim = pd.DataFrame(cos_sim, index=df.columns, columns=df.columns)\n",
    "    # Produce a Seaborn cluster map\n",
    "    cm = sns.clustermap(cos_sim, xticklabels=True, yticklabels=True)\n",
    "    plt.close(cm.figure)\n",
    "    # Get columns sorted based on the above heatmap clustering\n",
    "    sorted_cols = [t.get_text() for t in cm.ax_heatmap.xaxis.get_ticklabels()]\n",
    "\n",
    "    return sorted_cols\n",
    "\n",
    "\n",
    "def are_sequence_residues_valid(sequence):\n",
    "    return all(res in AMINO_ACIDS for res in sequence)\n",
    "\n",
    "\n",
    "def clean_carmen_db_allele_list(allele_list):\n",
    "    new_list = []\n",
    "    for i in range(len(allele_list)):\n",
    "        a = allele_list[i]\n",
    "        ccount = a.count(\":\")\n",
    "        if ccount == 0:\n",
    "            continue\n",
    "        elif ccount > 1:\n",
    "            new_list.append(\":\".join(a.split(\":\")[:2]))\n",
    "        elif a[-1].isalpha():\n",
    "            new_list.append(a[:-1])\n",
    "        else:\n",
    "            new_list.append(a)\n",
    "    return natsorted(set(new_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Subsidiary Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section should be run only once to re-create subsidiary files from core files for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populations Haplotype Frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a minor modification to the original file to make it more convenient to read later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_freqs(freqs, allele_cols, freqs_cols_org, freqs_cols_new):\n",
    "    # Take only columns with population frequencies\n",
    "    freqs = freqs[allele_cols + freqs_cols_org]\n",
    "    new_cols = {c_org: c for c_org, c in zip(freqs_cols_org, freqs_cols_new)}\n",
    "    freqs = freqs.rename(new_cols)\n",
    "\n",
    "    # Simplify allele name formats to be comparable with samples' haplotypes\n",
    "    freqs = freqs.with_columns(\n",
    "        pl.col(allele_cols)\n",
    "        .str.strip_suffix(\"L\")\n",
    "        .str.strip_suffix(\"N\")\n",
    "        .str.strip_suffix(\"Q\")\n",
    "        .str.strip_suffix(\"g\")\n",
    "    )\n",
    "\n",
    "    return freqs\n",
    "\n",
    "\n",
    "def read_mod_save_freqs(\n",
    "    freqs_org_file, allele_cols, freqs_out_file, freqs_cols_org, freqs_cols_new\n",
    "):\n",
    "    freqs = pl.read_excel(freqs_org_file)\n",
    "    freqs = clean_freqs(freqs, allele_cols, freqs_cols_org, freqs_cols_new)\n",
    "    freqs.write_csv(freqs_out_file)\n",
    "\n",
    "\n",
    "read_mod_save_freqs(\n",
    "    freqs_abc_org_file,\n",
    "    [freqs_col_a, freqs_col_b, freqs_col_c],\n",
    "    freqs_abc_file,\n",
    "    freqs_org_cols_freqs,\n",
    "    freqs_cols_freqs,\n",
    ")\n",
    "\n",
    "read_mod_save_freqs(\n",
    "    freqs_a_org_file,\n",
    "    [freqs_col_a],\n",
    "    freqs_a_file,\n",
    "    freqs_org_cols_freqs,\n",
    "    freqs_cols_freqs,\n",
    ")\n",
    "\n",
    "read_mod_save_freqs(\n",
    "    freqs_b_org_file,\n",
    "    [freqs_col_b],\n",
    "    freqs_b_file,\n",
    "    freqs_org_cols_freqs,\n",
    "    freqs_cols_freqs,\n",
    ")\n",
    "\n",
    "read_mod_save_freqs(\n",
    "    freqs_c_org_file,\n",
    "    [freqs_col_c],\n",
    "    freqs_c_file,\n",
    "    freqs_org_cols_freqs,\n",
    "    freqs_cols_freqs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pop_freqs_to_samples(samples):\n",
    "    binding_alleles = (\n",
    "        samples[samples_col_binding_alleles_clean]\n",
    "        .str.split(samples_list_sep)\n",
    "        .fill_null(list())\n",
    "    )\n",
    "\n",
    "    no_freq = pl.DataFrame(\n",
    "        [[None] * len(freqs_cols_freqs)], freqs_cols_freqs, orient=\"row\"\n",
    "    )\n",
    "\n",
    "    freqs_files_single = [freqs_a_file, freqs_b_file, freqs_c_file]\n",
    "    allele_col_list = [freqs_col_a, freqs_col_b, freqs_col_c]\n",
    "    new_freq_cols_list_1 = [\n",
    "        samples_cols_freqs_a,\n",
    "        samples_cols_freqs_b,\n",
    "        samples_cols_freqs_c,\n",
    "    ]\n",
    "\n",
    "    for freq_f, allele_col, new_freq_cols in tzip(\n",
    "        freqs_files_single,\n",
    "        allele_col_list,\n",
    "        new_freq_cols_list_1,\n",
    "        desc=\"Single freqs files\",\n",
    "        leave=False,\n",
    "    ):\n",
    "        freqs = pl.read_csv(freq_f)\n",
    "\n",
    "        sample_freqs = []\n",
    "\n",
    "        for alleles in tqdm(binding_alleles, desc=\"Allele lists\", leave=False):\n",
    "            sample_f = freqs.filter(pl.col(allele_col).is_in(alleles))\n",
    "\n",
    "            if sample_f.shape[0] != 0:\n",
    "                sample_f = sample_f.select(pl.col(freqs_cols_freqs)).sum()\n",
    "            else:\n",
    "                sample_f = no_freq.clone()\n",
    "\n",
    "            sample_freqs.append(sample_f)\n",
    "\n",
    "        sample_freqs = pl.concat(sample_freqs).fill_nan(None)\n",
    "\n",
    "        new_cols = {\n",
    "            org_c: new_c for org_c, new_c in zip(freqs_cols_freqs, new_freq_cols)\n",
    "        }\n",
    "        sample_freqs = sample_freqs.rename(new_cols)\n",
    "\n",
    "        samples = pl.concat([samples, sample_freqs], how=\"horizontal\")\n",
    "\n",
    "    del freqs, sample_freqs\n",
    "\n",
    "    # Set operations for including alleles in whole haplotypes\n",
    "    al_set_func_list = [\"any\", \"all\"]\n",
    "\n",
    "    new_freq_cols_list_3 = [samples_cols_freqs_abc_any, samples_cols_freqs_abc_all]\n",
    "\n",
    "    allele_cols = [freqs_col_a, freqs_col_b, freqs_col_c]\n",
    "\n",
    "    freqs = pl.read_csv(freqs_abc_file)\n",
    "\n",
    "    for al_set_func, new_freq_cols in tzip(\n",
    "        al_set_func_list,\n",
    "        new_freq_cols_list_3,\n",
    "        desc=\"ABC freqs set operations\",\n",
    "        leave=False,\n",
    "    ):\n",
    "        sample_freqs = []\n",
    "\n",
    "        for alleles in tqdm(binding_alleles, desc=\"Allele lists\", leave=False):\n",
    "            if al_set_func == \"all\":\n",
    "                sample_f = freqs.filter(\n",
    "                    pl.all_horizontal(pl.col(allele_cols).is_in(alleles))\n",
    "                )\n",
    "            elif al_set_func == \"any\":\n",
    "                sample_f = freqs.filter(\n",
    "                    pl.any_horizontal(pl.col(allele_cols).is_in(alleles))\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(\"Unknown set operation\")\n",
    "\n",
    "            if sample_f.shape[0] != 0:\n",
    "                sample_f = sample_f.select(pl.col(freqs_cols_freqs)).sum()\n",
    "            else:\n",
    "                sample_f = no_freq.clone()\n",
    "\n",
    "            sample_freqs.append(sample_f)\n",
    "\n",
    "        sample_freqs = pl.concat(sample_freqs).fill_nan(None)\n",
    "\n",
    "        new_cols = {\n",
    "            org_c: new_c for org_c, new_c in zip(freqs_cols_freqs, new_freq_cols)\n",
    "        }\n",
    "        sample_freqs = sample_freqs.rename(new_cols)\n",
    "\n",
    "        samples = pl.concat([samples, sample_freqs], how=\"horizontal\")\n",
    "\n",
    "    return samples, new_freq_cols_list_1, new_freq_cols_list_3\n",
    "\n",
    "\n",
    "def sort_samples(samples, new_freq_cols_list_1, new_freq_cols_list_3):\n",
    "    col_order = (\n",
    "        [\n",
    "            samples_col_sample_name,\n",
    "            samples_col_peptides,\n",
    "            samples_col_binding_alleles,\n",
    "            samples_col_peptides_9,\n",
    "            samples_col_umap_x,\n",
    "            samples_col_umap_y,\n",
    "            samples_col_label,\n",
    "            samples_col_binding_alleles_clean,\n",
    "        ]\n",
    "        + [c for cl in new_freq_cols_list_1 for c in cl]\n",
    "        + [c for cl in new_freq_cols_list_3 for c in cl]\n",
    "    )\n",
    "\n",
    "    return samples.select(pl.col(col_order))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_samples = pl.read_csv(main_samples_file, separator=\"\\t\")\n",
    "main_samples_2 = pl.read_csv(main_samples_file_2, separator=\"\\t\")\n",
    "\n",
    "samples_main = pl.concat(\n",
    "    [main_samples, main_samples_2.select(pl.col(main_samples_col_peptides))],\n",
    "    how=\"horizontal\",\n",
    ")\n",
    "del main_samples, main_samples_2\n",
    "\n",
    "samples_main = samples_main.with_columns(\n",
    "    pl.col(\n",
    "        [main_samples_col_binding_alleles, main_samples_col_peptides]\n",
    "    ).str.replace_all(main_samples_list_sep, samples_list_sep)\n",
    ")\n",
    "new_cols = {\n",
    "    main_samples_col_sample_name: samples_col_sample_name,\n",
    "    main_samples_col_binding_alleles: samples_col_binding_alleles,\n",
    "    main_samples_col_umap_x: samples_col_umap_x,\n",
    "    main_samples_col_umap_y: samples_col_umap_y,\n",
    "    main_samples_col_label: samples_col_label,\n",
    "    main_samples_col_peptides: samples_col_peptides,\n",
    "}\n",
    "samples_main = samples_main.rename(new_cols).sort(samples_col_sample_name)\n",
    "\n",
    "samples_main = samples_main.with_columns(\n",
    "    pl.col([samples_col_peptides, samples_col_binding_alleles])\n",
    "    .str.split(samples_list_sep)\n",
    "    .list.unique()\n",
    "    .map_elements(natsorted, return_dtype=pl.List(pl.String))\n",
    "    .list.join(samples_list_sep)\n",
    ")\n",
    "\n",
    "# Add filtered columns for peptides and alleles\n",
    "\n",
    "samples_main = samples_main.with_columns(\n",
    "    pl.col(samples_col_peptides)\n",
    "    .str.split(samples_list_sep)\n",
    "    .fill_null(list())\n",
    "    .map_elements(\n",
    "        lambda x: [\n",
    "            s for s in x if (are_sequence_residues_valid(s) and len(s) == peptide_len)\n",
    "        ],\n",
    "        return_dtype=pl.List(pl.String),\n",
    "    )\n",
    "    .list.sort()\n",
    "    .list.join(samples_list_sep)\n",
    "    .replace(\"\", None)\n",
    "    .alias(samples_col_peptides_9)\n",
    ")\n",
    "\n",
    "samples_main = samples_main.with_columns(\n",
    "    pl.col(samples_col_binding_alleles)\n",
    "    .str.split(samples_list_sep)\n",
    "    .fill_null(list())\n",
    "    .map_elements(clean_carmen_db_allele_list, return_dtype=pl.List(pl.String))\n",
    "    .list.join(samples_list_sep)\n",
    "    .replace(\"\", None)\n",
    "    .alias(samples_col_binding_alleles_clean)\n",
    ")\n",
    "\n",
    "# Add populations haplotype frequencies to samples\n",
    "\n",
    "samples_main, new_freq_cols_list_1, new_freq_cols_list_3 = add_pop_freqs_to_samples(\n",
    "    samples_main\n",
    ")\n",
    "\n",
    "# Sort columns and save\n",
    "\n",
    "samples_main = sort_samples(samples_main, new_freq_cols_list_1, new_freq_cols_list_3)\n",
    "\n",
    "samples_main.write_csv(samples_main_file)\n",
    "\n",
    "del samples_main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supplementary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part might take more time to calculate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare core samples data\n",
    "\n",
    "db_main = pl.read_csv(db_main_file, separator=\"\\t\")\n",
    "\n",
    "db_main = db_main.select(pl.col([\"Sample_name\", \"Peptide\", \"Haplotype\"])).sort(\n",
    "    \"Sample_name\"\n",
    ")\n",
    "\n",
    "grouped = db_main.group_by(\"Sample_name\", maintain_order=True)\n",
    "\n",
    "samples_peptides = (\n",
    "    grouped.agg(pl.col(\"Peptide\"))\n",
    "    .with_columns(\n",
    "        pl.col(\"Peptide\")\n",
    "        .list.unique()\n",
    "        .map_elements(natsorted, return_dtype=pl.List(pl.String))\n",
    "        .list.join(samples_list_sep)\n",
    "    )\n",
    "    .rename({\"Peptide\": samples_col_peptides})\n",
    "    .sort(\"Sample_name\")\n",
    ")\n",
    "\n",
    "samples_hlas = (\n",
    "    db_main[[\"Sample_name\", \"Haplotype\"]]\n",
    "    .unique()\n",
    "    .with_columns(\n",
    "        pl.col(\"Haplotype\")\n",
    "        .str.split(\",\")\n",
    "        .list.unique()\n",
    "        .map_elements(natsorted, return_dtype=pl.List(pl.String))\n",
    "        .list.join(samples_list_sep)\n",
    "    )\n",
    "    .rename({\"Haplotype\": samples_col_binding_alleles})\n",
    "    .sort(\"Sample_name\")\n",
    ")\n",
    "\n",
    "samples_supp = samples_peptides.with_columns(samples_hlas[samples_col_binding_alleles])\n",
    "\n",
    "del db_main, grouped, samples_hlas, samples_peptides\n",
    "\n",
    "# Add filtered columns for peptides and alleles\n",
    "\n",
    "samples_supp = samples_supp.with_columns(\n",
    "    pl.col(samples_col_peptides)\n",
    "    .str.split(samples_list_sep)\n",
    "    .fill_null(list())\n",
    "    .map_elements(\n",
    "        lambda x: [\n",
    "            s for s in x if (are_sequence_residues_valid(s) and len(s) == peptide_len)\n",
    "        ],\n",
    "        return_dtype=pl.List(pl.String),\n",
    "    )\n",
    "    .list.sort()\n",
    "    .list.join(samples_list_sep)\n",
    "    .replace(\"\", None)\n",
    "    .alias(samples_col_peptides_9)\n",
    ")\n",
    "\n",
    "samples_supp = samples_supp.with_columns(\n",
    "    pl.col(samples_col_binding_alleles)\n",
    "    .str.split(samples_list_sep)\n",
    "    .fill_null(list())\n",
    "    .map_elements(clean_carmen_db_allele_list, return_dtype=pl.List(pl.String))\n",
    "    .list.join(samples_list_sep)\n",
    "    .replace(\"\", None)\n",
    "    .alias(samples_col_binding_alleles_clean)\n",
    ")\n",
    "\n",
    "# Code peptides into PSSMs\n",
    "\n",
    "# Select normalization mode\n",
    "is_normalized = True\n",
    "\n",
    "# Select PSSM type\n",
    "halfbits = True\n",
    "hobohm_cluster = True\n",
    "\n",
    "samples_peptides = (\n",
    "    samples_supp[samples_col_peptides_9].str.split(samples_list_sep).fill_null(list())\n",
    ")\n",
    "\n",
    "no_pssm = [None] * (peptide_len * len(AMINO_ACIDS))\n",
    "\n",
    "samples_pssms = []\n",
    "\n",
    "for peptides in tqdm(samples_peptides, leave=False):\n",
    "    if len(peptides) == 0:\n",
    "        samples_pssms.append(no_pssm)\n",
    "        continue\n",
    "\n",
    "    pssm = strange_pssm(\n",
    "        peptides.to_list(), halfbits=halfbits, hobohm_cluster=hobohm_cluster\n",
    "    ).to_numpy()\n",
    "\n",
    "    if is_normalized:\n",
    "        pssm = pssm / np.abs(pssm).max()\n",
    "\n",
    "        # -1:1 option, for future reference\n",
    "        # below_zero = pssm < 0\n",
    "        # s = pssm[below_zero].reshape(-1, 1).tolist() + [[0.0]]\n",
    "        # s = MinMaxScaler(feature_range=(-1, 0)).fit_transform(s)\n",
    "        # pssm[below_zero] = s[:-1, 0]\n",
    "        # s = pssm[~below_zero].reshape(-1, 1).tolist() + [[0.0]]\n",
    "        # s = MinMaxScaler(feature_range=(0, 1)).fit_transform(s)\n",
    "        # pssm[~below_zero] = s[:-1, 0]\n",
    "\n",
    "    samples_pssms.append(pssm.flatten().tolist())\n",
    "\n",
    "del samples_peptides\n",
    "\n",
    "samples_pssms = pl.DataFrame(samples_pssms, orient=\"row\")\n",
    "new_cols = {f\"column_{i}\": f\"PSSM_{i}\" for i in range(samples_pssms.shape[1])}\n",
    "pssm_cols = [f\"PSSM_{i}\" for i in range(samples_pssms.shape[1])]\n",
    "samples_pssms = samples_pssms.rename(new_cols)\n",
    "\n",
    "samples_pssms = pl.concat(\n",
    "    [samples_supp.select(pl.col(samples_col_sample_name)), samples_pssms],\n",
    "    how=\"horizontal\",\n",
    ")\n",
    "\n",
    "# Create UMAP embedding\n",
    "\n",
    "# UMAP config\n",
    "umap_metric = \"cosine\"\n",
    "umap_n_neighbors = 50\n",
    "umap_min_dist = 0.4\n",
    "\n",
    "samples_pssms_clean = samples_pssms.filter(\n",
    "    ~pl.any_horizontal(pl.col(pssm_cols).is_null())\n",
    ")\n",
    "\n",
    "del samples_pssms\n",
    "\n",
    "reducer = umap.UMAP(\n",
    "    n_components=2,\n",
    "    n_neighbors=umap_n_neighbors,\n",
    "    min_dist=umap_min_dist,\n",
    "    metric=umap_metric,\n",
    "    random_state=random_seed,\n",
    "    n_jobs=1,\n",
    ").fit(samples_pssms_clean[pssm_cols].to_numpy())\n",
    "\n",
    "# Save the reducer for later, in case\n",
    "with open(umap_reducer_supp_file, \"wb\") as handle:\n",
    "    pickle.dump(reducer, handle)\n",
    "\n",
    "embedding = reducer.embedding_.copy()\n",
    "\n",
    "embedding = pl.concat(\n",
    "    [\n",
    "        samples_pssms_clean.select(pl.col(samples_col_sample_name)),\n",
    "        pl.DataFrame(\n",
    "            {samples_col_umap_x: embedding[:, 0], samples_col_umap_y: embedding[:, 1]}\n",
    "        ),\n",
    "    ],\n",
    "    how=\"horizontal\",\n",
    ")\n",
    "\n",
    "del samples_pssms_clean\n",
    "\n",
    "# Cluster the embedding points\n",
    "\n",
    "n_clusters = 19\n",
    "cluster_metric = \"cosine\"\n",
    "cluster_linkage = \"complete\"\n",
    "# cluster_memory = None\n",
    "cluster_memory = str(temp_dir)\n",
    "\n",
    "labels = (\n",
    "    AgglomerativeClustering(\n",
    "        n_clusters=n_clusters,\n",
    "        memory=cluster_memory,\n",
    "        metric=cluster_metric,\n",
    "        linkage=cluster_linkage,\n",
    "    )\n",
    "    .fit(embedding[samples_col_umap_x, samples_col_umap_y].to_numpy())\n",
    "    .labels_\n",
    ")\n",
    "\n",
    "samples_supp = pl.concat(\n",
    "    [\n",
    "        samples_supp,\n",
    "        pl.concat(\n",
    "            [embedding, pl.DataFrame({samples_col_label: labels})], how=\"horizontal\"\n",
    "        ),\n",
    "    ],\n",
    "    how=\"align\",\n",
    ")\n",
    "\n",
    "del embedding, labels\n",
    "\n",
    "# Add populations haplotype frequencies to samples\n",
    "\n",
    "samples_supp, new_freq_cols_list_1, new_freq_cols_list_3 = add_pop_freqs_to_samples(\n",
    "    samples_supp\n",
    ")\n",
    "\n",
    "# Sort columns and save\n",
    "\n",
    "samples_supp = sort_samples(samples_supp, new_freq_cols_list_1, new_freq_cols_list_3)\n",
    "\n",
    "samples_supp.write_csv(samples_supp_file)\n",
    "\n",
    "del samples_supp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MHC Motif Atlas Peptides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[MHC Motif Atlas](http://mhcmotifatlas.org) data to compare with the CARMEN database peptides.\n",
    "\n",
    "\"All Ligands\" option downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the source data and save only clean peptides of one length\n",
    "\n",
    "motif_atlas_peps = pl.read_csv(motif_atlas_peps_src_file, separator=\"\\t\")\n",
    "motif_atlas_peps = motif_atlas_peps.with_columns(\n",
    "    pl.col(motif_atlas_peps_col_peptide).str.to_uppercase()\n",
    ")\n",
    "\n",
    "# Filter out mouse alleles\n",
    "motif_atlas_peps = motif_atlas_peps.filter(\n",
    "    ~pl.col(motif_atlas_peps_col_allele).str.starts_with(\"H2-\")\n",
    ")\n",
    "\n",
    "# Get only clean peptides of one length\n",
    "motif_atlas_peps = motif_atlas_peps.filter(\n",
    "    (pl.col(motif_atlas_peps_col_peptide).str.len_chars() == peptide_len)\n",
    "    & (\n",
    "        pl.col(motif_atlas_peps_col_peptide).map_elements(\n",
    "            are_sequence_residues_valid, return_dtype=pl.Boolean\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "motif_atlas_peps.write_csv(motif_atlas_peps_file)\n",
    "\n",
    "del motif_atlas_peps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a file with UMAP embeddings for Motif Atlas peptides based on the supplementary model. Coordinates are saved per HLA allele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_atlas_peps = pl.read_csv(motif_atlas_peps_file)\n",
    "\n",
    "# Code peptides into PSSMs\n",
    "\n",
    "# Select normalization mode\n",
    "is_normalized = True\n",
    "\n",
    "# Select PSSM type\n",
    "halfbits = True\n",
    "hobohm_cluster = True\n",
    "\n",
    "unique_alleles = natsorted(motif_atlas_peps[motif_atlas_peps_col_allele].unique())\n",
    "\n",
    "alleles = []\n",
    "allele_pssms = []\n",
    "\n",
    "for u_a in tqdm(unique_alleles, leave=False):\n",
    "    peptides = (\n",
    "        motif_atlas_peps.filter(pl.col(motif_atlas_peps_col_allele) == u_a)[\n",
    "            motif_atlas_peps_col_peptide\n",
    "        ]\n",
    "        .unique()\n",
    "        .to_list()\n",
    "    )\n",
    "    peptides = sorted(peptides)\n",
    "\n",
    "    pssm = strange_pssm(\n",
    "        peptides, halfbits=halfbits, hobohm_cluster=hobohm_cluster\n",
    "    ).to_numpy()\n",
    "\n",
    "    if is_normalized:\n",
    "        pssm = pssm / np.abs(pssm).max()\n",
    "\n",
    "    alleles.append(u_a)\n",
    "    allele_pssms.append(pssm.flatten().tolist())\n",
    "\n",
    "del motif_atlas_peps, unique_alleles\n",
    "\n",
    "alleles = pl.DataFrame({supp_motif_atlas_emb_col_allele: alleles})\n",
    "\n",
    "allele_pssms = pl.DataFrame(allele_pssms, orient=\"row\")\n",
    "new_cols = {f\"column_{i}\": f\"PSSM_{i}\" for i in range(allele_pssms.shape[1])}\n",
    "pssm_cols = [f\"PSSM_{i}\" for i in range(allele_pssms.shape[1])]\n",
    "allele_pssms = allele_pssms.rename(new_cols)\n",
    "\n",
    "# Create UMAP embedding\n",
    "\n",
    "with open(umap_reducer_supp_file, \"rb\") as handle:\n",
    "    umap_reducer_supp = pickle.load(handle)\n",
    "\n",
    "embedding = umap_reducer_supp.transform(allele_pssms.to_numpy())\n",
    "\n",
    "del umap_reducer_supp, allele_pssms\n",
    "\n",
    "embedding = pl.DataFrame(\n",
    "    {\n",
    "        supp_motif_atlas_emb_col_x: embedding[:, 0],\n",
    "        supp_motif_atlas_emb_col_y: embedding[:, 1],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Save to disk\n",
    "\n",
    "pl.concat([alleles, embedding], how=\"horizontal\").write_csv(supp_motif_atlas_emb_file)\n",
    "\n",
    "del alleles, embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amino Acids Combinations in Peptides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might take a while to prepare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aa_on_positions(sequences, positions, first_pos_n=1):\n",
    "    positions = [pos - first_pos_n for pos in positions]\n",
    "\n",
    "    aa_combinations = []\n",
    "    for seq in sequences:\n",
    "        comb = \"\".join(np.array([a for a in seq])[positions])\n",
    "        aa_combinations.append(comb)\n",
    "\n",
    "    return aa_combinations\n",
    "\n",
    "\n",
    "def gather_indices(strings):\n",
    "    index_dict = {}\n",
    "    for i, s in enumerate(strings):\n",
    "        if s in index_dict:\n",
    "            index_dict[s].append(i)\n",
    "        else:\n",
    "            index_dict[s] = [i]\n",
    "    return index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pep_len = peptide_len\n",
    "\n",
    "pep_col = samples_col_peptides_9\n",
    "\n",
    "first_pos_n = 1\n",
    "\n",
    "# Get unique and clean peptides of one length\n",
    "\n",
    "samples = pl.read_csv(samples_supp_file)\n",
    "samples = samples.with_columns(\n",
    "    pl.col(samples_list_cols).str.split(samples_list_sep).fill_null(list())\n",
    ")\n",
    "samples = samples.filter(pl.col(pep_col).list.len() != 0)\n",
    "\n",
    "peptides = []\n",
    "for pep_list in samples[pep_col]:\n",
    "    peptides.extend(pep_list)\n",
    "peptides = np.array(sorted(set(peptides)))\n",
    "\n",
    "del samples\n",
    "\n",
    "# Get amino acids on all positions combinations\n",
    "\n",
    "n_positions = [n for n in range(1, pep_len)]\n",
    "# n_positions = [2, 3]\n",
    "\n",
    "pos_indexes = [n for n in range(first_pos_n, pep_len + first_pos_n)]\n",
    "\n",
    "aa_combs_all = []\n",
    "positions_all = []\n",
    "\n",
    "print(\"Gathering amino acids on positions\")\n",
    "for n_pos in tqdm(n_positions, leave=False, desc=\"Number of positions\"):\n",
    "    positions = list(itertools.combinations(pos_indexes, n_pos))\n",
    "\n",
    "    aa_combs = []\n",
    "    for pos in tqdm(positions, leave=False, desc=\"Specific positions\"):\n",
    "        c = get_aa_on_positions(peptides, pos, first_pos_n=first_pos_n)\n",
    "        aa_combs.append(c)\n",
    "\n",
    "    aa_combs_all.append(aa_combs)\n",
    "    positions_all.append(positions)\n",
    "\n",
    "# Create and save tables with all indices, amino acids, and associated peptides\n",
    "\n",
    "new_cols = {\n",
    "    \"column_0\": aa_combinations_col_pos,\n",
    "    \"column_1\": aa_combinations_col_aa,\n",
    "    \"column_2\": aa_combinations_col_pep,\n",
    "}\n",
    "\n",
    "sort_order = [aa_combinations_col_pos, aa_combinations_col_aa]\n",
    "\n",
    "print(\"Creating final tables\")\n",
    "for positions, aa_combs, n_pos in zip(\n",
    "    tqdm(positions_all, leave=False, desc=\"Positions\"), aa_combs_all, n_positions\n",
    "):\n",
    "    aa_combinations = []\n",
    "    for combs, pos in zip(tqdm(aa_combs, leave=False, desc=\"Combinations\"), positions):\n",
    "        pos_s = aa_combinations_list_sep.join([str(x) for x in pos])\n",
    "        pep_indices = gather_indices(combs)\n",
    "        df = pl.DataFrame(\n",
    "            [\n",
    "                [pos_s, aa_combinations_list_sep.join([a for a in comb])]\n",
    "                + [aa_combinations_list_sep.join(peptides[idxs].tolist())]\n",
    "                for comb, idxs in pep_indices.items()\n",
    "            ],\n",
    "            orient=\"row\",\n",
    "        )\n",
    "        aa_combinations.append(df)\n",
    "    aa_combinations = pl.concat(aa_combinations).rename(new_cols).sort(sort_order)\n",
    "    aa_combinations.write_csv(aa_combinations_file(n_pos))\n",
    "\n",
    "del aa_combs_all, positions_all, aa_combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publishable Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details about the contents of the published files presented in this section can be found in the `README.md` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peptide Clusters Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_remove = [samples_col_peptides_9, samples_col_binding_alleles_clean]\n",
    "\n",
    "samples_id_prefix = \"P_\"\n",
    "\n",
    "samples = pl.read_csv(samples_main_file)\n",
    "# samples = samples.select(pl.all().exclude(cols_to_remove))\n",
    "\n",
    "samples_ids = pl.DataFrame(\n",
    "    {samples_pub_col_id: [f\"{samples_id_prefix}{i+1}\" for i in range(samples.shape[0])]}\n",
    ")\n",
    "\n",
    "samples = pl.concat([samples_ids, samples], how=\"horizontal\")\n",
    "\n",
    "peptides_9 = samples.select(\n",
    "    pl.col(samples_pub_col_id),\n",
    "    pl.col(samples_col_peptides_9).str.split(samples_list_sep).fill_null(list()),\n",
    ")\n",
    "\n",
    "# Save without a couple of subsidiary columns\n",
    "samples.select(pl.all().exclude(cols_to_remove)).write_parquet(samples_pub_file)\n",
    "\n",
    "del samples, samples_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save an additional file with PSSMs of the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = []\n",
    "\n",
    "for row in tqdm(\n",
    "    peptides_9.iter_rows(named=True), total=peptides_9.shape[0], leave=False\n",
    "):\n",
    "    p_id = row[samples_pub_col_id]\n",
    "    peptides = row[samples_col_peptides_9]\n",
    "    if len(peptides) == 0:\n",
    "        pssm_json = \"{}\"\n",
    "    else:\n",
    "        pssm = info_pssm(peptides)\n",
    "        pssm.index = [i + 1 for i in range(pssm.shape[0])]\n",
    "        pssm_json = pssm.to_json()\n",
    "\n",
    "    json_str = f'\"{p_id}\":{pssm_json}'\n",
    "    json_list.append(json_str)\n",
    "\n",
    "del peptides_9\n",
    "\n",
    "json_str = \",\".join(json_list)\n",
    "json_str = \"{\" + json_str + \"}\"\n",
    "\n",
    "del json_list\n",
    "\n",
    "with open(samples_pub_pssms_file, \"w\") as handle:\n",
    "    handle.write(json_str)\n",
    "\n",
    "del json_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARMEN paper figures generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Motifs on UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates one core figure with the name `fig_name`, separate figures of motif for each label group in a directory named `fig_name`*-MOTIFS*, and a figure to help place the motifs under `fig_name`*-HELP*.\n",
    "\n",
    "This figure has two variations depending on which `samples` and `motif_atlas_emb` files you load.\n",
    "\n",
    "Final figure should be created in post-production by combining some of the above elements in a graphics editor software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which samples and MHC Atlas embeddings files to use\n",
    "\n",
    "# Main\n",
    "samples = pl.read_csv(samples_main_file)\n",
    "motif_atlas_emb = pl.read_csv(main_motif_atlas_emb_file, separator=\"\\t\").to_numpy()\n",
    "\n",
    "# Supplementary\n",
    "# samples = pl.read_csv(samples_supp_file)\n",
    "# motif_atlas_emb = (\n",
    "#     pl.read_csv(supp_motif_atlas_emb_file)\n",
    "#     .select(pl.col([supp_motif_atlas_emb_col_x, supp_motif_atlas_emb_col_y]))\n",
    "#     .to_numpy()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and select data\n",
    "\n",
    "samples = samples.with_columns(\n",
    "    pl.col(samples_list_cols).str.split(samples_list_sep).fill_null(list())\n",
    ")\n",
    "\n",
    "# Samples with UMAP data only\n",
    "samples = samples.filter(pl.col(samples_col_label).is_not_null())\n",
    "\n",
    "embedding = samples[samples_col_umap_x, samples_col_umap_y].to_numpy()\n",
    "labels = samples[samples_col_label].to_numpy()\n",
    "peptides = samples[samples_col_peptides_9].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure config\n",
    "\n",
    "fig_size = figsize_in_mm(max_fig_width_double_col * 0.45, max_fig_width_double_col * 0.45)\n",
    "\n",
    "fig_name = \"fig-2-umap-motifs\"\n",
    "\n",
    "logo_size_inside = (0.68, 0.48)\n",
    "logo_size_outside_x = 0.6\n",
    "logo_size_outside = figsize_in_mm(15 * logo_size_outside_x, 10 * logo_size_outside_x)\n",
    "\n",
    "point_size = default_point_size\n",
    "point_lw = 0.01\n",
    "\n",
    "atlas_point_size = point_size * 1.4\n",
    "\n",
    "legend_markersize = 4\n",
    "legend_font_size = 6\n",
    "\n",
    "clust_border_color = \"0.4\"\n",
    "clust_border_lw = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_cluster_motifs_umap(\n",
    "    embedding,\n",
    "    labels,\n",
    "    peptides,\n",
    "    fig_name,\n",
    "    save_motifs,\n",
    "    draw_borders,\n",
    "    mark_clusters,\n",
    "    draw_motifs,\n",
    "    atlas_emb=None,\n",
    "):\n",
    "    unique_labels = sorted(set(labels))\n",
    "    ul_len = len(unique_labels)\n",
    "    colors = color_pallet(ul_len)\n",
    "\n",
    "    fig = plt.figure(figsize=fig_size, layout=\"constrained\")\n",
    "\n",
    "    ax = fig.add_subplot()\n",
    "\n",
    "    for lab, c in zip(unique_labels, colors):\n",
    "        if lab == -1:\n",
    "            p_color = \"black\"\n",
    "        else:\n",
    "            p_color = c\n",
    "        mask = labels == lab\n",
    "        data = embedding[mask, :]\n",
    "        ax.scatter(\n",
    "            data[:, 0],\n",
    "            data[:, 1],\n",
    "            s=point_size,\n",
    "            alpha=1,\n",
    "            facecolors=p_color,\n",
    "            edgecolors=\"black\",\n",
    "            linewidths=point_lw,\n",
    "        )\n",
    "\n",
    "    if draw_borders:\n",
    "        for lab in unique_labels:\n",
    "            if lab == -1:\n",
    "                continue\n",
    "            mask = labels == lab\n",
    "            data = embedding[mask, :]\n",
    "            hull = ConvexHull(data)\n",
    "            for simplex in hull.simplices:\n",
    "                ax.plot(\n",
    "                    data[simplex, 0],\n",
    "                    data[simplex, 1],\n",
    "                    color=clust_border_color,\n",
    "                    lw=clust_border_lw,\n",
    "                )\n",
    "\n",
    "    if mark_clusters:\n",
    "        for lab in unique_labels:\n",
    "            if lab == -1:\n",
    "                continue\n",
    "            mask = labels == lab\n",
    "            data = embedding[mask, :]\n",
    "\n",
    "            x, y = calculate_centroid(data)\n",
    "\n",
    "            txt = ax.text(x, y, str(lab), ha=\"center\", va=\"center\", size=10)\n",
    "            txt.set_path_effects(\n",
    "                [PathEffects.withStroke(linewidth=2, foreground=\"white\")]\n",
    "            )\n",
    "\n",
    "    if save_motifs:\n",
    "        m_dir = figures_main_dir.joinpath(f\"{fig_name}-MOTIFS\")\n",
    "        m_dir.mkdir(parents=True, exist_ok=True)\n",
    "        for lab in unique_labels:\n",
    "            if lab == -1:\n",
    "                continue\n",
    "            mask = labels == lab\n",
    "            clustered_peptides = []\n",
    "            for pep_list in peptides[mask]:\n",
    "                clustered_peptides.extend(pep_list)\n",
    "            clustered_peptides = sorted(set(clustered_peptides))\n",
    "\n",
    "            fig_motif = plt.figure(figsize=logo_size_outside, layout=\"constrained\")\n",
    "            ax_motif = fig_motif.add_subplot()\n",
    "\n",
    "            ax_motif.spines[[\"right\", \"top\"]].set_visible(True)\n",
    "\n",
    "            logo = motif_logo(clustered_peptides, ax_motif)\n",
    "            logo.ax.set_xticks([])\n",
    "            logo.ax.set_yticks([])\n",
    "\n",
    "            fig_motif.patch.set_alpha(0)\n",
    "\n",
    "            # fig_motif.tight_layout()\n",
    "            fig_motif.get_layout_engine().set(w_pad=0, h_pad=0)\n",
    "\n",
    "            file_name = m_dir.joinpath(f\"{lab}.pdf\")\n",
    "            fig_motif.savefig(file_name, transparent=False)\n",
    "\n",
    "            plt.close(fig_motif)\n",
    "\n",
    "    if draw_motifs:\n",
    "        for lab in unique_labels:\n",
    "            if lab == -1:\n",
    "                continue\n",
    "            mask = labels == lab\n",
    "            data = embedding[mask, :]\n",
    "\n",
    "            x, y = calculate_centroid(data)\n",
    "\n",
    "            trans = fig.dpi_scale_trans + ScaledTranslation(x, y, ax.transData)\n",
    "\n",
    "            motif_ax = inset_axes(\n",
    "                ax,\n",
    "                width=\"100%\",\n",
    "                height=\"100%\",\n",
    "                bbox_to_anchor=(\n",
    "                    -logo_size_inside[0] / 2,\n",
    "                    -logo_size_inside[1] / 2,\n",
    "                    logo_size_inside[0],\n",
    "                    logo_size_inside[1],\n",
    "                ),\n",
    "                bbox_transform=trans,\n",
    "                borderpad=0,\n",
    "                axes_kwargs={\"anchor\": \"C\"},\n",
    "                loc=\"center\",\n",
    "            )\n",
    "\n",
    "            motif_ax.spines[[\"right\", \"top\"]].set_visible(True)\n",
    "\n",
    "            clustered_peptides = []\n",
    "            for pep_list in peptides[mask]:\n",
    "                clustered_peptides.extend(pep_list)\n",
    "            clustered_peptides = list(set(clustered_peptides))\n",
    "\n",
    "            logo = motif_logo(clustered_peptides, motif_ax)\n",
    "            logo.ax.set_xticks([])\n",
    "            logo.ax.set_yticks([])\n",
    "\n",
    "    if atlas_emb is not None:\n",
    "        ae = ax.scatter(\n",
    "            atlas_emb[:, 0],\n",
    "            atlas_emb[:, 1],\n",
    "            s=atlas_point_size,\n",
    "            color=\"black\",\n",
    "            marker=\"x\",\n",
    "        )\n",
    "\n",
    "        ae.set_path_effects([PathEffects.withStroke(linewidth=1.8, foreground=\"white\")])\n",
    "\n",
    "        legend_elements = [\n",
    "            Line2D(\n",
    "                [0],\n",
    "                [0],\n",
    "                marker=\"o\",\n",
    "                color=\"0.5\",\n",
    "                label=\"Sample\",\n",
    "                markersize=legend_markersize,\n",
    "                linestyle=\"\",\n",
    "            ),\n",
    "            Line2D(\n",
    "                [0],\n",
    "                [0],\n",
    "                marker=\"x\",\n",
    "                color=\"black\",\n",
    "                label=\"MHC Motif\\nAtlas allele\",\n",
    "                markersize=legend_markersize,\n",
    "                linestyle=\"\",\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        ax.legend(\n",
    "            handles=legend_elements,\n",
    "            loc=\"upper left\",\n",
    "            handletextpad=0.1,\n",
    "            fontsize=legend_font_size,\n",
    "        )\n",
    "\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    _ = ax.set_xlabel(\"UMAP_1\")\n",
    "    _ = ax.set_ylabel(\"UMAP_2\")\n",
    "\n",
    "    # ax.patch.set_alpha(0)\n",
    "    # fig.patch.set_alpha(0)\n",
    "\n",
    "    # fig.tight_layout()\n",
    "    fig.get_layout_engine().set(w_pad=0, h_pad=0)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core figure with separate motif figures\n",
    "\n",
    "save_motifs = True\n",
    "draw_borders = False\n",
    "mark_clusters = False\n",
    "draw_motifs = False\n",
    "\n",
    "fig = draw_cluster_motifs_umap(\n",
    "    embedding,\n",
    "    labels,\n",
    "    peptides,\n",
    "    fig_name,\n",
    "    save_motifs,\n",
    "    draw_borders,\n",
    "    mark_clusters,\n",
    "    draw_motifs,\n",
    "    atlas_emb=motif_atlas_emb,\n",
    ")\n",
    "file_name = figures_main_dir.joinpath(f\"{fig_name}.pdf\")\n",
    "fig.savefig(file_name)\n",
    "\n",
    "# Helper figure\n",
    "\n",
    "save_motifs = False\n",
    "draw_borders = True\n",
    "mark_clusters = True\n",
    "draw_motifs = False\n",
    "\n",
    "fig = draw_cluster_motifs_umap(\n",
    "    embedding,\n",
    "    labels,\n",
    "    peptides,\n",
    "    fig_name,\n",
    "    save_motifs,\n",
    "    draw_borders,\n",
    "    mark_clusters,\n",
    "    draw_motifs,\n",
    ")\n",
    "file_name = figures_main_dir.joinpath(f\"{fig_name}-HELP.pdf\")\n",
    "fig.savefig(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Frequencies on UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates one core figure with the name `fig_name`, separate figures of motif for each label group in a directory named `fig_name`*-MOTIFS*, and a figure to help place the motifs under `fig_name`*-HELP*.\n",
    "\n",
    "This figure has two variations depending on which `samples` file you load.\n",
    "\n",
    "Final figure should be created in post-production by combining some of the above elements in a graphics editor software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which samples file to use\n",
    "\n",
    "# Main\n",
    "samples = pl.read_csv(samples_main_file)\n",
    "\n",
    "# Supplementary\n",
    "# samples = pl.read_csv(samples_supp_file)\n",
    "\n",
    "# Select which frequency data to use\n",
    "\n",
    "# samples_cols_freqs = samples_cols_freqs_a  # Only A* alleles\n",
    "# samples_cols_freqs = samples_cols_freqs_b  # Only B* alleles\n",
    "# samples_cols_freqs = samples_cols_freqs_c  # Only C* alleles\n",
    "# samples_cols_freqs = samples_cols_freqs_abc_any  # A+B+C union\n",
    "samples_cols_freqs = samples_cols_freqs_abc_all  # A+B+C intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and select data\n",
    "\n",
    "samples = samples.with_columns(\n",
    "    pl.col(samples_list_cols).str.split(samples_list_sep).fill_null(list())\n",
    ")\n",
    "\n",
    "# Samples with UMAP data only\n",
    "samples = samples.filter(pl.col(samples_col_label).is_not_null())\n",
    "\n",
    "freqs = samples[samples_cols_freqs]\n",
    "new_cols = {c: c.split(\"_\")[1] for c in freqs.columns}\n",
    "freqs = freqs.rename(new_cols)\n",
    "\n",
    "freqs_not_null = freqs.select(pl.all_horizontal(pl.col(\"*\").is_not_null())).to_series()\n",
    "\n",
    "freqs = freqs.filter(freqs_not_null)\n",
    "embedding = samples.filter(freqs_not_null)[\n",
    "    samples_col_umap_x, samples_col_umap_y\n",
    "].to_numpy()\n",
    "labels = samples.filter(freqs_not_null)[samples_col_label].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure config\n",
    "\n",
    "fig_size = figsize_in_mm(max_fig_width_double_col * 0.45, max_fig_width_double_col * 0.4)\n",
    "\n",
    "fig_name = \"fig-2-umap-freqs\"\n",
    "\n",
    "heatmap_size_inside = (0.2, 0.2)\n",
    "heatmap_size_outside = figsize_in_mm(6, 6)\n",
    "\n",
    "point_size = default_point_size\n",
    "point_lw = 0.01\n",
    "\n",
    "clust_border_color = \"0.4\"\n",
    "clust_border_lw = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_cluster_freqs_umap(\n",
    "    embedding,\n",
    "    labels,\n",
    "    freqs,\n",
    "    fig_name,\n",
    "    save_heatmaps,\n",
    "    draw_borders,\n",
    "    mark_clusters,\n",
    "    draw_heatmaps,\n",
    "):\n",
    "    unique_labels = sorted(set(labels))\n",
    "    ul_len = len(unique_labels)\n",
    "    colors = color_pallet(ul_len)\n",
    "\n",
    "    # Change the ordering based on clustering\n",
    "    pop_order = cos_sim_clustermap_order(freqs)\n",
    "    freqs_sorted = freqs.select(pl.col(pop_order))\n",
    "\n",
    "    # Get min and max values of cosine similarity for all clusters\n",
    "    v_min = np.inf\n",
    "    v_max = -np.inf\n",
    "    for lab in unique_labels:\n",
    "        mask = labels == lab\n",
    "        mask_freqs = freqs_sorted.to_numpy()[mask, :]\n",
    "        cos_s = cosine_similarity(mask_freqs.T)\n",
    "        c_min = cos_s.min()\n",
    "        if c_min < v_min:\n",
    "            v_min = c_min\n",
    "        c_max = cos_s.max()\n",
    "        if c_max > v_max:\n",
    "            v_max = c_max\n",
    "\n",
    "    fig = plt.figure(figsize=fig_size, layout=\"constrained\")\n",
    "\n",
    "    ax = fig.add_subplot()\n",
    "\n",
    "    for lab, c in zip(unique_labels, colors):\n",
    "        if lab == -1:\n",
    "            p_color = \"black\"\n",
    "        else:\n",
    "            p_color = c\n",
    "        mask = labels == lab\n",
    "        data = embedding[mask, :]\n",
    "        ax.scatter(\n",
    "            data[:, 0],\n",
    "            data[:, 1],\n",
    "            s=point_size,\n",
    "            alpha=1,\n",
    "            facecolors=p_color,\n",
    "            edgecolors=\"black\",\n",
    "            linewidths=point_lw,\n",
    "        )\n",
    "\n",
    "    if draw_borders:\n",
    "        for lab in unique_labels:\n",
    "            if lab == -1:\n",
    "                continue\n",
    "            mask = labels == lab\n",
    "            data = embedding[mask, :]\n",
    "            hull = ConvexHull(data)\n",
    "            for simplex in hull.simplices:\n",
    "                ax.plot(\n",
    "                    data[simplex, 0],\n",
    "                    data[simplex, 1],\n",
    "                    color=clust_border_color,\n",
    "                    lw=clust_border_lw,\n",
    "                )\n",
    "\n",
    "    if mark_clusters:\n",
    "        for lab in unique_labels:\n",
    "            if lab == -1:\n",
    "                continue\n",
    "            mask = labels == lab\n",
    "            data = embedding[mask, :]\n",
    "\n",
    "            x, y = calculate_centroid(data)\n",
    "\n",
    "            txt = ax.text(x, y, str(lab), ha=\"center\", va=\"center\", size=10)\n",
    "            txt.set_path_effects(\n",
    "                [PathEffects.withStroke(linewidth=2, foreground=\"white\")]\n",
    "            )\n",
    "\n",
    "    if save_heatmaps:\n",
    "        hm_dir = figures_main_dir.joinpath(f\"{fig_name}-HEATMAPS\")\n",
    "        hm_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for lab in unique_labels:\n",
    "            if lab == -1:\n",
    "                continue\n",
    "            mask = labels == lab\n",
    "            mask_freqs = freqs_sorted.to_numpy()[mask, :]\n",
    "            cos_s = cosine_similarity(mask_freqs.T)\n",
    "\n",
    "            fig_hm = plt.figure(figsize=heatmap_size_outside, layout=\"constrained\")\n",
    "            ax_hm = fig_hm.add_subplot()\n",
    "\n",
    "            ax_hm.spines[[\"right\", \"top\"]].set_visible(True)\n",
    "\n",
    "            _ = ax_hm.imshow(\n",
    "                cos_s,\n",
    "                aspect=\"equal\",\n",
    "                vmin=v_min,\n",
    "                vmax=v_max,\n",
    "                interpolation=\"none\",\n",
    "                cmap=\"magma\",\n",
    "            )\n",
    "\n",
    "            ax_hm.set_xticks([], labels=[])\n",
    "            ax_hm.set_yticks([], labels=[])\n",
    "\n",
    "            fig_hm.patch.set_alpha(0)\n",
    "\n",
    "            fig_hm.get_layout_engine().set(w_pad=0, h_pad=0)\n",
    "\n",
    "            file_name = hm_dir.joinpath(f\"{lab}.pdf\")\n",
    "            fig_hm.savefig(file_name, transparent=False)\n",
    "\n",
    "            plt.close(fig_hm)\n",
    "\n",
    "    if draw_heatmaps:\n",
    "        for lab in unique_labels:\n",
    "            if lab == -1:\n",
    "                continue\n",
    "            mask = labels == lab\n",
    "            data = embedding[mask, :]\n",
    "            mask_freqs = freqs_sorted.to_numpy()[mask, :]\n",
    "            cos_s = cosine_similarity(mask_freqs.T)\n",
    "\n",
    "            x, y = calculate_centroid(data)\n",
    "\n",
    "            trans = fig.dpi_scale_trans + ScaledTranslation(x, y, ax.transData)\n",
    "\n",
    "            ax_hm = inset_axes(\n",
    "                ax,\n",
    "                width=\"100%\",\n",
    "                height=\"100%\",\n",
    "                bbox_to_anchor=(\n",
    "                    -heatmap_size_inside[0] / 2,\n",
    "                    -heatmap_size_inside[1] / 2,\n",
    "                    heatmap_size_inside[0],\n",
    "                    heatmap_size_inside[1],\n",
    "                ),\n",
    "                bbox_transform=trans,\n",
    "                borderpad=0,\n",
    "                axes_kwargs={\"anchor\": \"C\"},\n",
    "                loc=\"center\",\n",
    "            )\n",
    "\n",
    "            ax_hm.spines[[\"right\", \"top\"]].set_visible(True)\n",
    "\n",
    "            _ = ax_hm.imshow(\n",
    "                cos_s,\n",
    "                aspect=\"equal\",\n",
    "                vmin=v_min,\n",
    "                vmax=v_max,\n",
    "                interpolation=\"none\",\n",
    "                cmap=\"magma\",\n",
    "            )\n",
    "\n",
    "            ax_hm.set_xticks([])\n",
    "            ax_hm.set_yticks([])\n",
    "\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    _ = ax.set_xlabel(\"UMAP_1\")\n",
    "    _ = ax.set_ylabel(\"UMAP_2\")\n",
    "\n",
    "    _ = fig.colorbar(\n",
    "        plt.cm.ScalarMappable(norm=plt.Normalize(vmin=v_min, vmax=v_max), cmap=\"magma\"),\n",
    "        ax=ax,\n",
    "        label=\"Cosine similarity\",\n",
    "        shrink=0.5,\n",
    "    )\n",
    "\n",
    "    fig.get_layout_engine().set(w_pad=0, h_pad=0)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core figure with separate motif figures\n",
    "\n",
    "save_heatmaps = True\n",
    "draw_borders = False\n",
    "mark_clusters = False\n",
    "draw_heatmaps = False\n",
    "\n",
    "fig = draw_cluster_freqs_umap(\n",
    "    embedding,\n",
    "    labels,\n",
    "    freqs,\n",
    "    fig_name,\n",
    "    save_heatmaps,\n",
    "    draw_borders,\n",
    "    mark_clusters,\n",
    "    draw_heatmaps,\n",
    ")\n",
    "file_name = figures_main_dir.joinpath(f\"{fig_name}.pdf\")\n",
    "fig.savefig(file_name)\n",
    "\n",
    "# Helper figure\n",
    "\n",
    "save_heatmaps = False\n",
    "draw_borders = True\n",
    "mark_clusters = True\n",
    "draw_heatmaps = False\n",
    "\n",
    "fig = draw_cluster_freqs_umap(\n",
    "    embedding,\n",
    "    labels,\n",
    "    freqs,\n",
    "    fig_name,\n",
    "    save_heatmaps,\n",
    "    draw_borders,\n",
    "    mark_clusters,\n",
    "    draw_heatmaps,\n",
    ")\n",
    "file_name = figures_main_dir.joinpath(f\"{fig_name}-HELP.pdf\")\n",
    "fig.savefig(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequencies Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we produce three figures: NMDP Registry Haplotype Frequencies populations similarity heatmap, CARMEN database samples similarity heatmap, and another figure with a colorbar referring to both previous figures attached to it.\n",
    "\n",
    "Final figure should be created in post-production by combining some of the above elements in a graphics editor software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Haplotype Frequencies Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate haplotype frequencies similarity\n",
    "\n",
    "# Select which frequency data to use\n",
    "\n",
    "# freqs = pl.read_csv(freqs_a_file)  # Only A* alleles\n",
    "# freqs = pl.read_csv(freqs_b_file)  # Only B* alleles\n",
    "# freqs = pl.read_csv(freqs_c_file)  # Only C* alleles\n",
    "freqs = pl.read_csv(freqs_abc_file)  # A+B+C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the selected dataset\n",
    "\n",
    "# Just take the frequencies and change names\n",
    "freqs = freqs.select(pl.col(freqs_cols_freqs))\n",
    "new_cols = {c: c.split(\"_\")[1] for c in freqs.columns}\n",
    "freqs = freqs.rename(new_cols)\n",
    "\n",
    "# Calculate cosine similarity for the populations\n",
    "cos_sim_haplo = cosine_similarity(freqs.transpose())\n",
    "cos_sim_haplo = pd.DataFrame(cos_sim_haplo, index=freqs.columns, columns=freqs.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CARMEN Frequencies Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate CARMEN samples frequencies similarity\n",
    "\n",
    "# Select which samples file to use\n",
    "\n",
    "# Main\n",
    "samples = pl.read_csv(samples_main_file)\n",
    "\n",
    "# Supplementary\n",
    "# samples = pl.read_csv(samples_supp_file)\n",
    "\n",
    "# Select which frequency data to use:\n",
    "\n",
    "# samples_cols_freqs = samples_cols_freqs_a  # Only A* alleles\n",
    "# samples_cols_freqs = samples_cols_freqs_b  # Only B* alleles\n",
    "# samples_cols_freqs = samples_cols_freqs_c  # Only C* alleles\n",
    "# samples_cols_freqs = samples_cols_freqs_abc_any  # A+B+C union\n",
    "samples_cols_freqs = samples_cols_freqs_abc_all  # A+B+C intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the selected dataset\n",
    "\n",
    "samples = samples.with_columns(\n",
    "    pl.col(samples_list_cols).str.split(samples_list_sep).fill_null(list())\n",
    ")\n",
    "\n",
    "freqs = samples[samples_cols_freqs].filter(pl.all_horizontal(pl.col(\"*\").is_not_null()))\n",
    "new_cols = {c: c.split(\"_\")[1] for c in freqs.columns}\n",
    "freqs = freqs.rename(new_cols)\n",
    "\n",
    "# Calculate cosine similarity for the samples\n",
    "cos_sim_carmen = cosine_similarity(freqs.transpose())\n",
    "cos_sim_carmen = pd.DataFrame(\n",
    "    cos_sim_carmen, index=freqs.columns, columns=freqs.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the minimum and maximum values from both tables\n",
    "v_min = min(cos_sim_haplo.min().min(), cos_sim_carmen.min().min())\n",
    "v_max = max(cos_sim_haplo.max().max(), cos_sim_carmen.max().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Haplotype Frequencies Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure config\n",
    "\n",
    "fig_size = figsize_in_mm(max_fig_width_double_col * 0.35, max_fig_width_double_col * 0.35)\n",
    "\n",
    "fig_name = \"fig-2-freq-sim-haplo\"\n",
    "\n",
    "cm_font_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a Seaborn cluster map\n",
    "\n",
    "cm = sns.clustermap(\n",
    "    cos_sim_haplo,\n",
    "    figsize=fig_size,\n",
    "    xticklabels=True,\n",
    "    yticklabels=True,\n",
    "    vmin=v_min,\n",
    "    vmax=v_max,\n",
    ")\n",
    "\n",
    "cm.ax_heatmap.xaxis.set_tick_params(labelsize=cm_font_size)\n",
    "cm.ax_heatmap.yaxis.set_tick_params(labelsize=cm_font_size)\n",
    "\n",
    "cm.cax.set_visible(False)\n",
    "# cm.ax_row_dendrogram.set_visible(False)\n",
    "cm.ax_col_dendrogram.set_visible(False)\n",
    "\n",
    "file_name = figures_main_dir.joinpath(f\"{fig_name}.pdf\")\n",
    "cm.figure.savefig(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CARMEN Frequencies Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure config\n",
    "\n",
    "# fig_size = figsize_in_mm(max_fig_width_double_col * 0.35, max_fig_width_double_col * 0.35)\n",
    "\n",
    "fig_name = \"fig-2-freq-sim-carmen\"\n",
    "\n",
    "# cm_font_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a Seaborn cluster map\n",
    "\n",
    "cm = sns.clustermap(\n",
    "    cos_sim_carmen,\n",
    "    figsize=fig_size,\n",
    "    xticklabels=True,\n",
    "    yticklabels=True,\n",
    "    vmin=v_min,\n",
    "    vmax=v_max,\n",
    ")\n",
    "\n",
    "cm.ax_heatmap.xaxis.set_tick_params(labelsize=cm_font_size)\n",
    "cm.ax_heatmap.yaxis.set_tick_params(labelsize=cm_font_size)\n",
    "\n",
    "cm.cax.set_visible(False)\n",
    "# cm.ax_row_dendrogram.set_visible(False)\n",
    "cm.ax_col_dendrogram.set_visible(False)\n",
    "\n",
    "file_name = figures_main_dir.joinpath(f\"{fig_name}.pdf\")\n",
    "cm.figure.savefig(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Colorbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure config\n",
    "\n",
    "# fig_size = figsize_in_mm(max_fig_width_double_col * 0.35, max_fig_width_double_col * 0.35)\n",
    "\n",
    "fig_name = \"fig-2-freq-sim-colorbar\"\n",
    "\n",
    "# cm_font_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a Seaborn cluster map\n",
    "\n",
    "# cbar_kws={\"orientation\": \"horizontal\"}\n",
    "# cbar_pos=(0.25, 0.92, 0.5, 0.03)\n",
    "cbar_kws = {\"orientation\": \"vertical\"}\n",
    "cbar_pos = (-0.03, 0.0, 0.03, 0.35)\n",
    "\n",
    "cm = sns.clustermap(\n",
    "    cos_sim_carmen,\n",
    "    figsize=fig_size,\n",
    "    xticklabels=True,\n",
    "    yticklabels=True,\n",
    "    vmin=v_min,\n",
    "    vmax=v_max,\n",
    "    cbar_kws=cbar_kws,\n",
    "    cbar_pos=cbar_pos,\n",
    ")\n",
    "\n",
    "_ = cm.ax_cbar.set_ylabel(\"Cosine similarity\", labelpad=3, size=cm_font_size)\n",
    "cm.ax_cbar.yaxis.set_tick_params(labelsize=cm_font_size)\n",
    "\n",
    "cm.ax_cbar.spines[\"outline\"].set(visible=True, lw=0.8)\n",
    "\n",
    "cm.ax_row_dendrogram.set_visible(False)\n",
    "cm.ax_col_dendrogram.set_visible(False)\n",
    "\n",
    "cm.ax_heatmap.clear()\n",
    "cm.ax_heatmap.set_axis_off()\n",
    "\n",
    "file_name = figures_main_dir.joinpath(f\"{fig_name}.pdf\")\n",
    "cm.figure.savefig(file_name, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CARMEN vs. MHC Motif Atlas Peptides Venn Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary data\n",
    "\n",
    "samples = pl.read_csv(samples_supp_file)\n",
    "samples = samples.with_columns(\n",
    "    pl.col(samples_list_cols).str.split(samples_list_sep).fill_null(list())\n",
    ")\n",
    "samples = samples.filter(pl.col(samples_col_peptides_9).list.len() != 0)\n",
    "\n",
    "peptides_carmen = []\n",
    "for pep_list in samples[samples_col_peptides_9]:\n",
    "    peptides_carmen.extend(pep_list)\n",
    "peptides_carmen = set(peptides_carmen)\n",
    "\n",
    "del samples\n",
    "\n",
    "motif_atlas_peps = pl.read_csv(motif_atlas_peps_file)\n",
    "\n",
    "peptides_atlas = set(motif_atlas_peps[motif_atlas_peps_col_peptide].to_list())\n",
    "\n",
    "del motif_atlas_peps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure config\n",
    "\n",
    "fig_size = figsize_in_mm(max_fig_width_double_col * 0.2, max_fig_width_double_col * 0.1)\n",
    "\n",
    "fig_name = \"fig-2-carmen-vs-motif-atlas-venn\"\n",
    "\n",
    "venn_label_font_size = 6\n",
    "venn_num_font_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = [peptides_carmen, peptides_atlas]\n",
    "\n",
    "set_labels = (\"CARMEN\\npeptides\", \"MHC\\nMotif Atlas\\npeptides\")\n",
    "\n",
    "fig = plt.figure(figsize=fig_size, layout=\"constrained\")\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "v = venn2(\n",
    "    subsets,\n",
    "    ax=ax,\n",
    "    set_labels=set_labels,\n",
    "    set_colors=(\"C0\", \"C1\"),\n",
    "    alpha=1,\n",
    "    subset_label_formatter=lambda n: f\"{n:,}\",\n",
    ")\n",
    "\n",
    "v.set_labels[0].set_fontsize(venn_label_font_size)\n",
    "v.set_labels[1].set_fontsize(venn_label_font_size)\n",
    "\n",
    "v.get_label_by_id(\"10\").set_fontsize(venn_num_font_size)\n",
    "v.get_label_by_id(\"11\").set_fontsize(venn_num_font_size)\n",
    "v.get_label_by_id(\"01\").set_fontsize(venn_num_font_size)\n",
    "\n",
    "# Change some label positions\n",
    "p = v.set_labels[1].get_position()\n",
    "v.set_labels[1].set_position((p[0] + 0.25, p[1] + 0.15))\n",
    "\n",
    "p = v.get_label_by_id(\"10\").get_position()\n",
    "v.get_label_by_id(\"10\").set_position((p[0] - 0.2, p[1]))\n",
    "\n",
    "p = v.get_label_by_id(\"11\").get_position()\n",
    "v.get_label_by_id(\"11\").set_position((p[0], p[1] + 0.2))\n",
    "\n",
    "p = v.get_label_by_id(\"01\").get_position()\n",
    "v.get_label_by_id(\"01\").set_position((p[0] + 0.25, p[1]))\n",
    "\n",
    "fig.get_layout_engine().set(w_pad=0, h_pad=0)\n",
    "\n",
    "file_name = figures_main_dir.joinpath(f\"{fig_name}.pdf\")\n",
    "fig.savefig(file_name, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populations Frequencies UMAPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which samples file to use\n",
    "\n",
    "# Main\n",
    "samples = pl.read_csv(samples_main_file)\n",
    "\n",
    "# Supplementary\n",
    "# samples = pl.read_csv(samples_supp_file)\n",
    "\n",
    "# Select which frequency data to use\n",
    "\n",
    "# samples_cols_freqs = samples_cols_freqs_a  # Only A* alleles\n",
    "# samples_cols_freqs = samples_cols_freqs_b  # Only B* alleles\n",
    "# samples_cols_freqs = samples_cols_freqs_c  # Only C* alleles\n",
    "# samples_cols_freqs = samples_cols_freqs_abc_any  # A+B+C union\n",
    "samples_cols_freqs = samples_cols_freqs_abc_all  # A+B+C intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and select data\n",
    "\n",
    "samples = samples.with_columns(\n",
    "    pl.col(samples_list_cols).str.split(samples_list_sep).fill_null(list())\n",
    ")\n",
    "\n",
    "# Samples with UMAP data only\n",
    "samples = samples.filter(pl.col(samples_col_label).is_not_null())\n",
    "\n",
    "freqs = samples[samples_cols_freqs]\n",
    "new_cols = {c: c.split(\"_\")[1] for c in freqs.columns}\n",
    "freqs = freqs.rename(new_cols)\n",
    "\n",
    "freqs_not_null = freqs.select(pl.all_horizontal(pl.col(\"*\").is_not_null())).to_series()\n",
    "\n",
    "freqs = freqs.filter(freqs_not_null)\n",
    "embedding = samples.filter(freqs_not_null)[\n",
    "    samples_col_umap_x, samples_col_umap_y\n",
    "].to_numpy()\n",
    "labels = samples.filter(freqs_not_null)[samples_col_label].to_numpy()\n",
    "\n",
    "# Change the ordering based on clustering\n",
    "pop_order = cos_sim_clustermap_order(freqs)\n",
    "freqs = freqs.select(pl.col(pop_order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure config\n",
    "\n",
    "fig_size = figsize_in_mm(max_fig_width_double_col*0.92, max_max_fig_height*0.38)\n",
    "\n",
    "fig_name = \"fig-2-umaps-pop-freqs\"\n",
    "\n",
    "point_size = 2\n",
    "# point_lw = 0.01\n",
    "point_alpha = 1\n",
    "\n",
    "clust_border_color = \"0.3\"\n",
    "clust_border_lw = 0.1\n",
    "clust_border_alpha = 0.3\n",
    "\n",
    "gs_grid = (4, 7)  # (nrows, ncols); there are 21 populations\n",
    "\n",
    "pop_label_size = 6\n",
    "pop_label_x = 0.98\n",
    "pop_label_y = 0.96\n",
    "pop_label_kwargs = dict(ha=\"right\", va=\"top\", color=\"black\", size=pop_label_size)\n",
    "\n",
    "x_label_hori_i = 3\n",
    "y_label_vert_i = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save figure\n",
    "\n",
    "populations = freqs.columns\n",
    "unique_labels = sorted(set(labels))\n",
    "norm = plt.matplotlib.colors.Normalize(\n",
    "    vmin=freqs.min().min_horizontal().item(), vmax=freqs.max().max_horizontal().item()\n",
    ")\n",
    "\n",
    "fig = plt.figure(figsize=fig_size, layout=\"constrained\")\n",
    "\n",
    "gs = fig.add_gridspec(nrows=gs_grid[0], ncols=gs_grid[1], hspace=0, wspace=0)\n",
    "axs = gs.subplots(sharex=\"col\", sharey=\"row\")\n",
    "\n",
    "axes_to_populate = [\n",
    "    3,\n",
    "    4,\n",
    "    5,\n",
    "    6,\n",
    "    9,\n",
    "    10,\n",
    "    11,\n",
    "    12,\n",
    "    13,\n",
    "    16,\n",
    "    17,\n",
    "    18,\n",
    "    19,\n",
    "    20,\n",
    "    21,\n",
    "    22,\n",
    "    23,\n",
    "    24,\n",
    "    25,\n",
    "    26,\n",
    "    27,\n",
    "]\n",
    "\n",
    "for ax, pop in zip(axs.flatten()[axes_to_populate], populations):\n",
    "    for lab in unique_labels:\n",
    "        if lab == -1:\n",
    "            continue\n",
    "        mask = labels == lab\n",
    "        data = embedding[mask, :]\n",
    "        hull = ConvexHull(data)\n",
    "        for simplex in hull.simplices:\n",
    "            ax.plot(\n",
    "                data[simplex, 0],\n",
    "                data[simplex, 1],\n",
    "                color=clust_border_color,\n",
    "                lw=clust_border_lw,\n",
    "                alpha=clust_border_alpha,\n",
    "            )\n",
    "\n",
    "    ax.spines[[\"right\", \"top\"]].set_visible(True)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    pop_freqs = freqs[pop].to_numpy()\n",
    "\n",
    "    sorted_idx = np.argsort(pop_freqs)\n",
    "\n",
    "    sc = ax.scatter(\n",
    "        embedding[sorted_idx, 0],\n",
    "        embedding[sorted_idx, 1],\n",
    "        s=point_size,\n",
    "        alpha=point_alpha,\n",
    "        c=pop_freqs[sorted_idx],\n",
    "        norm=norm,\n",
    "        cmap=\"Reds\",\n",
    "    )\n",
    "\n",
    "    ax.text(pop_label_x, pop_label_y, pop, transform=ax.transAxes, **pop_label_kwargs)\n",
    "\n",
    "axs[-1][x_label_hori_i].set_xlabel(\"UMAP_1\")\n",
    "axs[y_label_vert_i][0].set_ylabel(\"UMAP_2\")\n",
    "\n",
    "# Automatically delete last unused axes\n",
    "# n_ax_to_del = gs_grid[0] * gs_grid[1] - len(populations)\n",
    "# if n_ax_to_del != 0:\n",
    "#     for ax in axs.flatten()[-n_ax_to_del :]:\n",
    "#         ax.set_axis_off()\n",
    "\n",
    "# Automatically delete unused axes\n",
    "axes_to_del = list(\n",
    "    set([i for i in range(gs_grid[0] * gs_grid[1])]) - set(axes_to_populate)\n",
    ")\n",
    "for ax in axs.flatten()[axes_to_del]:\n",
    "    ax.set_axis_off()\n",
    "\n",
    "# _ = fig.colorbar(sc, label=\"Frequency\", orientation=\"horizontal\", ax=axs, shrink=0.25, pad=0.012)\n",
    "\n",
    "# cb_ax = axs[-1][1].inset_axes([-0.2, -0.4, 1, 0.15])\n",
    "# cb_ax = fig.add_axes((0.325, -0.026, 0.4, 0.015))\n",
    "# _ = fig.colorbar(sc, label=\"Frequency\", orientation=\"horizontal\", cax=cb_ax)\n",
    "\n",
    "fig.get_layout_engine().set(w_pad=0, h_pad=0, hspace=0, wspace=0)\n",
    "\n",
    "file_name = figures_main_dir.joinpath(f\"{fig_name}.pdf\")\n",
    "fig.savefig(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a colorbar separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure config\n",
    "\n",
    "fig_name = \"fig-2-umaps-pop-freqs-colorbar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save figure\n",
    "\n",
    "fig = plt.figure(figsize=fig_size, layout=\"constrained\")\n",
    "\n",
    "gs = fig.add_gridspec(nrows=gs_grid[0], ncols=gs_grid[1], hspace=0, wspace=0)\n",
    "axs = gs.subplots(sharex=\"col\", sharey=\"row\")\n",
    "\n",
    "pop_freqs = freqs[populations[0]].to_numpy()\n",
    "\n",
    "sc = axs.flatten()[0].scatter(\n",
    "    embedding[:, 0],\n",
    "    embedding[:, 1],\n",
    "    s=point_size,\n",
    "    alpha=point_alpha,\n",
    "    c=pop_freqs,\n",
    "    norm=norm,\n",
    "    cmap=\"Reds\",\n",
    ")\n",
    "\n",
    "axs[-1][x_label_hori_i].set_xlabel(\"UMAP_1\")\n",
    "axs[y_label_vert_i][0].set_ylabel(\"UMAP_2\")\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.clear()\n",
    "    ax.set_axis_off()\n",
    "\n",
    "_ = fig.colorbar(sc, label=\"Frequency\", orientation=\"horizontal\", ax=axs, shrink=0.25, pad=0.012)\n",
    "\n",
    "fig.get_layout_engine().set(w_pad=0, h_pad=0, hspace=0, wspace=0)\n",
    "\n",
    "file_name = figures_main_dir.joinpath(f\"{fig_name}.pdf\")\n",
    "fig.savefig(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AA Combination Frequency (single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the number of positions option to draw\n",
    "\n",
    "n_positions = 2\n",
    "\n",
    "# Select cut-off threshold for annotating the cumulative percent of peptides coverage\n",
    "\n",
    "sum_margin = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare necessary data\n",
    "\n",
    "pep_perc_col = \"Peptides_perc\"\n",
    "\n",
    "pep_col = samples_col_peptides_9\n",
    "\n",
    "pep_len = peptide_len\n",
    "\n",
    "blank_char = \"_\"\n",
    "\n",
    "first_pos_n = 1\n",
    "\n",
    "# Get unique peptides\n",
    "samples = pl.read_csv(samples_supp_file)\n",
    "samples = samples.with_columns(\n",
    "    pl.col(samples_list_cols).str.split(samples_list_sep).fill_null(list())\n",
    ")\n",
    "samples = samples.filter(pl.col(pep_col).list.len() != 0)\n",
    "peptides = []\n",
    "for pep_list in samples[pep_col]:\n",
    "    peptides.extend(pep_list)\n",
    "peptides = np.array(sorted(set(peptides)))\n",
    "del samples\n",
    "\n",
    "peptides_n = len(peptides)\n",
    "\n",
    "# Prepare the amino acids combinations table\n",
    "aa_combinations = pl.read_csv(aa_combinations_file(n_positions))\n",
    "aa_combinations = aa_combinations.with_columns(\n",
    "    pl.col(aa_combinations_col_pep).str.split(aa_combinations_list_sep)\n",
    ")\n",
    "\n",
    "if n_positions == 1:\n",
    "    aa_combinations = aa_combinations.with_columns(\n",
    "        pl.col(aa_combinations_col_pos).cast(pl.List(int)),\n",
    "        pl.col(aa_combinations_col_aa).str.split(\";\"),\n",
    "    )\n",
    "else:\n",
    "    aa_combinations = aa_combinations.with_columns(\n",
    "        pl.col(aa_combinations_col_pos).str.split(\";\").cast(pl.List(int)),\n",
    "        pl.col(aa_combinations_col_aa).str.split(\";\"),\n",
    "    )\n",
    "\n",
    "aa_combinations = aa_combinations.with_columns(\n",
    "    (pl.col(aa_combinations_col_pep).list.len() / peptides_n * 100).alias(pep_perc_col)\n",
    ")\n",
    "aa_combinations = aa_combinations.sort(pep_perc_col, descending=True)\n",
    "\n",
    "comb_n = aa_combinations.shape[0]\n",
    "\n",
    "# Get the cumulative percent of peptides coverage\n",
    "peptide_coverage = []\n",
    "pep_c = set()\n",
    "for pep_list in aa_combinations[aa_combinations_col_pep]:\n",
    "    pep_c.update(pep_list)\n",
    "    p_perc = len(pep_c) / peptides_n * 100\n",
    "    if p_perc >= 100:\n",
    "        n_left = aa_combinations.shape[0] - len(peptide_coverage)\n",
    "        peptide_coverage.extend([100.0] * n_left)\n",
    "        break\n",
    "    peptide_coverage.append(p_perc)\n",
    "peptide_coverage = np.array(peptide_coverage)\n",
    "\n",
    "# Check the above threshold index\n",
    "above_margin_idx = np.where(peptide_coverage >= sum_margin)[0][0]\n",
    "# margin_diff = peptide_coverage[above_margin_idx] - sum_margin\n",
    "# prev_diff = peptide_coverage[above_margin_idx] - peptide_coverage[above_margin_idx - 1]\n",
    "# margin_val = above_margin_idx - margin_diff / prev_diff\n",
    "\n",
    "below_margin_comb_perc = (above_margin_idx + 1) / comb_n * 100\n",
    "\n",
    "# Make \"fake\" peptides from amino acids combinations below threshold only\n",
    "blank_pep = np.array([blank_char] * pep_len)\n",
    "\n",
    "below_margin_aa_combs = aa_combinations.slice(0, above_margin_idx + 1)\n",
    "\n",
    "comb_peps = []\n",
    "for i in range(below_margin_aa_combs.shape[0]):\n",
    "    row = below_margin_aa_combs.row(i)\n",
    "    new_pep = blank_pep.copy()\n",
    "    new_pep[np.array(row[0]) - first_pos_n] = row[1]\n",
    "    comb_peps.append(\"\".join(new_pep))\n",
    "\n",
    "# Create a PSSM table out of those peptides\n",
    "comb_peps_pssm = info_pssm(comb_peps, alphabet=AMINO_ACIDS + [blank_char])\n",
    "aa_cols = comb_peps_pssm.columns.to_list()\n",
    "aa_cols.remove(blank_char)\n",
    "comb_peps_pssm = comb_peps_pssm.loc[:, aa_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure config\n",
    "\n",
    "fig_size = figsize_in_mm(max_fig_width_double_col * 0.434, max_fig_width_double_col * 0.25)\n",
    "\n",
    "fig_name = \"fig-2-aa-combinations-coverage-single\"\n",
    "\n",
    "marker_size = 3\n",
    "\n",
    "logo_x = 0.85\n",
    "logo_size = (70 / 72 * logo_x, 50 / 72 * logo_x)  # Pixels\n",
    "logo_location = (0.77, 0.71)\n",
    "logo_font_size = 5\n",
    "\n",
    "sum_annot_color = \"black\"\n",
    "sum_annot_linewidth = 0.5\n",
    "sum_annot_font_size = 6\n",
    "sum_annot_arrow_x_offset = 100\n",
    "sum_annot_arrow_lenth = 10\n",
    "sum_annot_arrowprops = dict(\n",
    "    facecolor=sum_annot_color, headwidth=3, headlength=3, width=0.1\n",
    ")\n",
    "sum_annot_arrow_pos_pep = 0.42\n",
    "sum_annot_arrow_pos_comb = 0.26\n",
    "\n",
    "ax2_linewidth = 1\n",
    "ax2_color = \"0.4\"\n",
    "\n",
    "axes_x_margin = 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make figure\n",
    "\n",
    "fig = plt.figure(figsize=fig_size, layout=\"constrained\")\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "_ = ax.set_ylabel(\"Peptide coverage (%)\")\n",
    "_ = ax.set_xlabel(\"Amino acids and positions combination\")\n",
    "\n",
    "x = np.arange(comb_n)\n",
    "\n",
    "# Make each indices combination have its own color\n",
    "unique_pos = aa_combinations[aa_combinations_col_pos].unique(maintain_order=True)\n",
    "unique_pos_n = len(unique_pos)\n",
    "\n",
    "colors = color_pallet(unique_pos_n)\n",
    "\n",
    "comb_colors = []\n",
    "for pos in aa_combinations[aa_combinations_col_pos]:\n",
    "    c_idx = np.where(unique_pos == pos.to_list())[0][0]\n",
    "    comb_colors.append(colors[c_idx])\n",
    "\n",
    "_ = ax.scatter(x, aa_combinations[pep_perc_col], s=marker_size, c=comb_colors)\n",
    "\n",
    "# Cumulative frequency of occurrence\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "ax2.spines[\"right\"].set_visible(True)\n",
    "ax2.spines[\"right\"].set_color(ax2_color)\n",
    "ax2.tick_params(axis=\"y\", colors=ax2_color)\n",
    "\n",
    "_ = ax2.set_ylabel(\"Cumulative peptide\\ncoverage (%)\", color=ax2_color, labelpad=0)\n",
    "\n",
    "_ = ax2.plot(peptide_coverage, color=ax2_color, linewidth=ax2_linewidth)\n",
    "\n",
    "# X% peptide sum annotations\n",
    "\n",
    "_ = ax2.axvline(above_margin_idx, color=sum_annot_color, linewidth=sum_annot_linewidth)\n",
    "\n",
    "ybound = ax.get_ybound()\n",
    "\n",
    "_ = ax.annotate(\n",
    "    f\"{sum_margin}% of peptides\",\n",
    "    xy=(\n",
    "        above_margin_idx + sum_annot_arrow_x_offset,\n",
    "        ybound[0] + (ybound[1] - ybound[0]) * sum_annot_arrow_pos_pep,\n",
    "    ),\n",
    "    xytext=(sum_annot_arrow_lenth, 0),\n",
    "    textcoords=\"offset points\",\n",
    "    ha=\"left\",\n",
    "    va=\"center\",\n",
    "    fontsize=sum_annot_font_size,\n",
    "    color=sum_annot_color,\n",
    "    arrowprops=sum_annot_arrowprops,\n",
    ")\n",
    "\n",
    "_ = ax.annotate(\n",
    "    f\"{below_margin_comb_perc:.2f}% of combinations\\n(\"\n",
    "    + r\"$\\bf{\"\n",
    "    + f\"{above_margin_idx+1:,}\"\n",
    "    + \"}$)\",\n",
    "    xy=(\n",
    "        above_margin_idx + sum_annot_arrow_x_offset,\n",
    "        ybound[0] + (ybound[1] - ybound[0]) * sum_annot_arrow_pos_comb,\n",
    "    ),\n",
    "    xytext=(sum_annot_arrow_lenth, 0),\n",
    "    textcoords=\"offset points\",\n",
    "    ha=\"left\",\n",
    "    va=\"center\",\n",
    "    fontsize=sum_annot_font_size,\n",
    "    color=sum_annot_color,\n",
    "    arrowprops=sum_annot_arrowprops,\n",
    ")\n",
    "\n",
    "ax.margins(x=axes_x_margin)\n",
    "ax2.margins(x=axes_x_margin)\n",
    "\n",
    "# Motif logo\n",
    "\n",
    "trans = fig.dpi_scale_trans + ScaledTranslation(\n",
    "    logo_location[0], logo_location[1], ax.transAxes\n",
    ")\n",
    "motif_ax = inset_axes(\n",
    "    ax,\n",
    "    width=\"100%\",\n",
    "    height=\"100%\",\n",
    "    bbox_to_anchor=(\n",
    "        -logo_size[0] / 2,\n",
    "        -logo_size[1] / 2,\n",
    "        logo_size[0],\n",
    "        logo_size[1],\n",
    "    ),\n",
    "    bbox_transform=trans,\n",
    "    borderpad=0,\n",
    "    axes_kwargs={\"anchor\": \"C\"},\n",
    "    loc=\"center\",\n",
    ")\n",
    "\n",
    "motif_ax.spines[[\"right\", \"top\"]].set_visible(True)\n",
    "\n",
    "# Create a motif from amino acids combinations below threshold only\n",
    "logo = logomaker.Logo(\n",
    "    comb_peps_pssm,\n",
    "    color_scheme=\"weblogo_protein\",\n",
    "    stack_order=\"big_on_top\",\n",
    "    flip_below=False,\n",
    "    center_values=False,\n",
    "    baseline_width=0,\n",
    "    vpad=0.05,\n",
    "    ax=motif_ax,\n",
    ")\n",
    "\n",
    "logo.ax.set_xticks(range(0, pep_len), labels=[str(i) for i in range(1, pep_len + 1)])\n",
    "logo.ax.xaxis.set_tick_params(length=0)\n",
    "_ = logo.ax.set_ylabel(\"Bits\", size=logo_font_size, labelpad=0)\n",
    "logo.ax.tick_params(axis=\"both\", labelsize=logo_font_size)\n",
    "\n",
    "fig.get_layout_engine().set(w_pad=0, h_pad=0, hspace=0, wspace=0)\n",
    "\n",
    "file_name = figures_main_dir.joinpath(f\"{fig_name}.pdf\")\n",
    "fig.savefig(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section produces only parts of the whole Figure 3 panel. The rest can be found elsewhere.\n",
    "\n",
    "This is only to produce base figures, to be finalized in a graphic editing software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning ROC Curve 1-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "ml_roc_curve_1_1_hla = pl.read_csv(ml_roc_curve_1_1_hla_file)\n",
    "ml_roc_curve_1_1_no_hla = pl.read_csv(ml_roc_curve_1_1_no_hla_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure config\n",
    "\n",
    "fig_size = figsize_in_mm(85, 40)\n",
    "\n",
    "fig_name = \"fig-3-ml-roc-curve-1-1\"\n",
    "\n",
    "line_color_hla = \"C5\"\n",
    "line_color_no_hla = \"C9\"\n",
    "\n",
    "linewidth_hla = 3\n",
    "linewidth_no_hla = 1\n",
    "\n",
    "legend_fontsize = 6\n",
    "\n",
    "auc_rounding = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save figure\n",
    "\n",
    "fig = plt.figure(figsize=fig_size, layout=\"constrained\")\n",
    "\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "x = ml_roc_curve_1_1_hla[ml_roc_curve_col_x]\n",
    "y = ml_roc_curve_1_1_hla[ml_roc_curve_col_y]\n",
    "auc = np.trapz(y, x)\n",
    "label = f\"With HLA (AUC={auc:.{auc_rounding}f})\"\n",
    "_ = ax.plot(x, y, color=line_color_hla, label=label, linewidth=linewidth_hla)\n",
    "\n",
    "x = ml_roc_curve_1_1_no_hla[ml_roc_curve_col_x]\n",
    "y = ml_roc_curve_1_1_no_hla[ml_roc_curve_col_y]\n",
    "auc = np.trapz(y, x)\n",
    "label = f\"Without HLA (AUC={auc:.{auc_rounding}f})\"\n",
    "_ = ax.plot(x, y, color=line_color_no_hla, label=label, linewidth=linewidth_no_hla)\n",
    "\n",
    "ax.legend(fontsize=legend_fontsize)\n",
    "\n",
    "_ = ax.set_xlabel(\"False positive rate\")\n",
    "_ = ax.set_ylabel(\"True positive rate\")\n",
    "\n",
    "fig.get_layout_engine().set(w_pad=0, h_pad=0)\n",
    "\n",
    "file_name = figures_main_dir.joinpath(f\"{fig_name}.pdf\")\n",
    "fig.savefig(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning ROC Curve 1-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "ml_roc_curve_1_5_hla = pl.read_csv(ml_roc_curve_1_5_hla_file)\n",
    "ml_roc_curve_1_5_no_hla = pl.read_csv(ml_roc_curve_1_5_no_hla_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure config\n",
    "\n",
    "fig_size = figsize_in_mm(85, 40)\n",
    "\n",
    "fig_name = \"fig-3-ml-roc-curve-1-5\"\n",
    "\n",
    "line_color_hla = \"C5\"\n",
    "line_color_no_hla = \"C9\"\n",
    "\n",
    "linewidth_hla = 3\n",
    "linewidth_no_hla = 1\n",
    "\n",
    "legend_fontsize = 6\n",
    "\n",
    "auc_rounding = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save figure\n",
    "\n",
    "fig = plt.figure(figsize=fig_size, layout=\"constrained\")\n",
    "\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "x = ml_roc_curve_1_5_hla[ml_roc_curve_col_x]\n",
    "y = ml_roc_curve_1_5_hla[ml_roc_curve_col_y]\n",
    "auc = np.trapz(y, x)\n",
    "label = f\"With HLA (AUC={auc:.{auc_rounding}f})\"\n",
    "_ = ax.plot(x, y, color=line_color_hla, label=label, linewidth=linewidth_hla)\n",
    "\n",
    "x = ml_roc_curve_1_5_no_hla[ml_roc_curve_col_x]\n",
    "y = ml_roc_curve_1_5_no_hla[ml_roc_curve_col_y]\n",
    "auc = np.trapz(y, x)\n",
    "label = f\"Without HLA (AUC={auc:.{auc_rounding}f})\"\n",
    "_ = ax.plot(x, y, color=line_color_no_hla, label=label, linewidth=linewidth_no_hla)\n",
    "\n",
    "ax.legend(fontsize=legend_fontsize)\n",
    "\n",
    "_ = ax.set_xlabel(\"False positive rate\")\n",
    "_ = ax.set_ylabel(\"True positive rate\")\n",
    "\n",
    "fig.get_layout_engine().set(w_pad=0, h_pad=0)\n",
    "\n",
    "file_name = figures_main_dir.joinpath(f\"{fig_name}.pdf\")\n",
    "fig.savefig(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusters' Peptide Intersection (UMAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which samples file to use\n",
    "\n",
    "# Main\n",
    "samples = pl.read_csv(samples_main_file)\n",
    "\n",
    "# Supplementary\n",
    "# samples = pl.read_csv(samples_supp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "\n",
    "peptides_col = samples_col_peptides_9\n",
    "\n",
    "samples = samples.with_columns(\n",
    "    pl.col(samples_list_cols).str.split(samples_list_sep).fill_null(list())\n",
    ")\n",
    "\n",
    "# Samples with UMAP data only\n",
    "samples = samples.filter(pl.col(samples_col_label).is_not_null())\n",
    "\n",
    "embedding = samples[samples_col_umap_x, samples_col_umap_y].to_numpy()\n",
    "labels = samples[samples_col_label].to_numpy()\n",
    "peptides = samples[peptides_col].to_numpy()\n",
    "\n",
    "del samples\n",
    "\n",
    "unique_labels = sorted(set(labels))\n",
    "\n",
    "all_cluster_peps_col_label = \"Label\"\n",
    "all_cluster_peps_col_peps = \"Peptides\"\n",
    "all_cluster_peps_col_x_perc = lambda label: f\"Perc_{label}\"\n",
    "all_cluster_peps_cols_x_perc = [all_cluster_peps_col_x_perc(ul) for ul in unique_labels]\n",
    "\n",
    "common_peps_perc_c_name = lambda label: f\"C_{label}\"\n",
    "\n",
    "# Gather all cluster peptides\n",
    "all_cluster_peps = []\n",
    "for lab in unique_labels:\n",
    "    mask = labels == lab\n",
    "    clustered_peptides = []\n",
    "    for pep_list in peptides[mask]:\n",
    "        clustered_peptides.extend(pep_list)\n",
    "    clustered_peptides = list(set(clustered_peptides))\n",
    "    all_cluster_peps.append(clustered_peptides)\n",
    "\n",
    "all_cluster_peps = pl.DataFrame(\n",
    "    {\n",
    "        all_cluster_peps_col_label: unique_labels,\n",
    "        all_cluster_peps_col_peps: all_cluster_peps,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Calculate the percent of common peptides between clusters\n",
    "common_peps_perc = []\n",
    "\n",
    "for lab_org in unique_labels:\n",
    "    row_org = all_cluster_peps.filter(\n",
    "        pl.col(all_cluster_peps_col_label) == lab_org\n",
    "    ).row(0, named=True)\n",
    "    peps_org = row_org[all_cluster_peps_col_peps]\n",
    "\n",
    "    peps_org_n = len(peps_org)\n",
    "\n",
    "    c_peps_perc = []\n",
    "\n",
    "    for lab in unique_labels:\n",
    "        row = all_cluster_peps.filter(pl.col(all_cluster_peps_col_label) == lab).row(\n",
    "            0, named=True\n",
    "        )\n",
    "        peps = row[all_cluster_peps_col_peps]\n",
    "\n",
    "        n_common = len(set(peps_org).intersection(set(peps)))\n",
    "\n",
    "        c_peps_perc.append(n_common / peps_org_n * 100)\n",
    "\n",
    "    common_peps_perc.append(c_peps_perc)\n",
    "\n",
    "all_cluster_peps = pl.concat(\n",
    "    [all_cluster_peps, pl.DataFrame(common_peps_perc, all_cluster_peps_cols_x_perc)],\n",
    "    how=\"horizontal\",\n",
    ")\n",
    "\n",
    "# Prepare a table with common percentage\n",
    "common_peps_perc = (\n",
    "    all_cluster_peps.with_columns(\n",
    "        pl.col(all_cluster_peps_col_label)\n",
    "        .cast(pl.String)\n",
    "        .map_elements(lambda x: common_peps_perc_c_name(x), return_dtype=pl.String)\n",
    "    )\n",
    "    .select(pl.col(all_cluster_peps_col_label), pl.col(all_cluster_peps_cols_x_perc))\n",
    "    .rename({all_cluster_peps_col_x_perc(ul): common_peps_perc_c_name(ul) for ul in unique_labels})\n",
    "    .to_pandas()\n",
    "    .set_index(all_cluster_peps_col_label)\n",
    ")\n",
    "common_peps_perc.index.name = \"\"\n",
    "\n",
    "del all_cluster_peps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the original cluster IDs\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5), layout=\"constrained\")\n",
    "\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "colors = color_pallet(len(unique_labels))\n",
    "\n",
    "for lab, c in zip(unique_labels, colors):\n",
    "    if lab == -1:\n",
    "        continue\n",
    "    mask = labels == lab\n",
    "    data = embedding[mask, :]\n",
    "\n",
    "    hull = ConvexHull(data)\n",
    "    ax.fill(\n",
    "        [data[vert, 0] for vert in hull.vertices],\n",
    "        [data[vert, 1] for vert in hull.vertices],\n",
    "        color=c,\n",
    "    )\n",
    "\n",
    "    x, y = calculate_centroid(data)\n",
    "    txt = ax.text(\n",
    "        x,\n",
    "        y,\n",
    "        common_peps_perc_c_name(lab),\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        size=8,\n",
    "        color=\"black\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map original IDs to new ones to be changed later on\n",
    "\n",
    "clust_id_map = {\n",
    "    \"C_7\": \"C_1\",\n",
    "    \"C_14\": \"C_2\",\n",
    "    \"C_5\": \"C_3\",\n",
    "    \"C_9\": \"C_4\",\n",
    "    \"C_1\": \"C_5\",\n",
    "    \"C_0\": \"C_6\",\n",
    "    \"C_6\": \"C_7\",\n",
    "    \"C_11\": \"C_8\",\n",
    "    \"C_3\": \"C_9\",\n",
    "    \"C_8\": \"C_10\",\n",
    "    \"C_13\": \"C_11\",\n",
    "    \"C_2\": \"C_12\",\n",
    "    \"C_10\": \"C_13\",\n",
    "    \"C_4\": \"C_14\",\n",
    "    \"C_12\": \"C_15\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure config\n",
    "\n",
    "fig_size = figsize_in_mm(40, 40)\n",
    "\n",
    "fig_name = \"fig-3-clusters-peptides-umap\"\n",
    "\n",
    "header_fontsize = 6\n",
    "header_color = \"black\"\n",
    "\n",
    "axis_label_fontsize = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the common peptides table to add appropriate info later\n",
    "\n",
    "# Round the numbers\n",
    "dec_p = 1\n",
    "common_peps_perc=common_peps_perc.round(dec_p)\n",
    "\n",
    "common_peps_perc = common_peps_perc.rename(columns=clust_id_map).rename(\n",
    "    index=clust_id_map\n",
    ")\n",
    "\n",
    "file_name = figures_main_dir.joinpath(f\"{fig_name}-HELP.csv\")\n",
    "common_peps_perc.to_csv(file_name, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save figure\n",
    "\n",
    "fig = plt.figure(figsize=fig_size, layout=\"constrained\")\n",
    "\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "colors = color_pallet(len(unique_labels))\n",
    "\n",
    "for lab, c in zip(unique_labels, colors):\n",
    "    if lab == -1:\n",
    "        continue\n",
    "    mask = labels == lab\n",
    "    data = embedding[mask, :]\n",
    "\n",
    "    hull = ConvexHull(data)\n",
    "    ax.fill(\n",
    "        [data[vert, 0] for vert in hull.vertices],\n",
    "        [data[vert, 1] for vert in hull.vertices],\n",
    "        color=c,\n",
    "    )\n",
    "\n",
    "    x, y = calculate_centroid(data)\n",
    "    txt = ax.text(\n",
    "        x,\n",
    "        y,\n",
    "        clust_id_map[common_peps_perc_c_name(lab)],\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        size=header_fontsize,\n",
    "        color=header_color,\n",
    "    )\n",
    "\n",
    "ax.margins(x=0.01, y=0.01)\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "_ = ax.set_xlabel(\"UMAP_1\", fontsize=axis_label_fontsize)\n",
    "_ = ax.set_ylabel(\"UMAP_2\", fontsize=axis_label_fontsize)\n",
    "\n",
    "fig.get_layout_engine().set(w_pad=0, h_pad=0)\n",
    "\n",
    "file_name = figures_main_dir.joinpath(f\"{fig_name}.pdf\")\n",
    "fig.savefig(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusters' Peptide Intersection (All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which samples file to use\n",
    "\n",
    "# Main\n",
    "samples = pl.read_csv(samples_main_file)\n",
    "\n",
    "# Supplementary\n",
    "# samples = pl.read_csv(samples_supp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "\n",
    "peptides_col = samples_col_peptides_9\n",
    "\n",
    "samples = samples.with_columns(\n",
    "    pl.col(samples_list_cols).str.split(samples_list_sep).fill_null(list())\n",
    ")\n",
    "\n",
    "# Samples with UMAP data only\n",
    "samples = samples.filter(pl.col(samples_col_label).is_not_null())\n",
    "\n",
    "labels = samples[samples_col_label].to_numpy()\n",
    "peptides = samples[peptides_col].to_numpy()\n",
    "\n",
    "del samples\n",
    "\n",
    "unique_labels = sorted(set(labels))\n",
    "\n",
    "all_cluster_peps_col_label = \"Label\"\n",
    "all_cluster_peps_col_peps = \"Peptides\"\n",
    "all_cluster_peps_col_x_perc = lambda label: f\"Perc_{label}\"\n",
    "all_cluster_peps_cols_x_perc = [all_cluster_peps_col_x_perc(ul) for ul in unique_labels]\n",
    "\n",
    "common_peps_perc_c_name = lambda label: f\"C_{label}\"\n",
    "\n",
    "common_peps_perc_all_col_label = \"Label\"\n",
    "common_peps_perc_all_col_perc = \"Perc_all\"\n",
    "\n",
    "# Gather all cluster peptides\n",
    "all_cluster_peps = []\n",
    "for lab in unique_labels:\n",
    "    mask = labels == lab\n",
    "    clustered_peptides = []\n",
    "    for pep_list in peptides[mask]:\n",
    "        clustered_peptides.extend(pep_list)\n",
    "    clustered_peptides = list(set(clustered_peptides))\n",
    "    all_cluster_peps.append(clustered_peptides)\n",
    "\n",
    "all_cluster_peps = pl.DataFrame(\n",
    "    {\n",
    "        all_cluster_peps_col_label: unique_labels,\n",
    "        all_cluster_peps_col_peps: all_cluster_peps,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Calculate the percent of common peptides between clusters\n",
    "common_peps_perc = []\n",
    "common_peps_perc_all = []\n",
    "\n",
    "for lab_org in unique_labels:\n",
    "    row_org = all_cluster_peps.filter(\n",
    "        pl.col(all_cluster_peps_col_label) == lab_org\n",
    "    ).row(0, named=True)\n",
    "    peps_org = row_org[all_cluster_peps_col_peps]\n",
    "\n",
    "    peps_org_n = len(peps_org)\n",
    "\n",
    "    c_peps_perc = []\n",
    "    c_peps_all = []\n",
    "\n",
    "    for lab in unique_labels:\n",
    "        row = all_cluster_peps.filter(pl.col(all_cluster_peps_col_label) == lab).row(\n",
    "            0, named=True\n",
    "        )\n",
    "        peps = row[all_cluster_peps_col_peps]\n",
    "\n",
    "        n_common = len(set(peps_org).intersection(set(peps)))\n",
    "        c_peps_perc.append(n_common / peps_org_n * 100)\n",
    "\n",
    "        if lab != lab_org:\n",
    "            c_peps_all.extend(peps)\n",
    "\n",
    "    common_peps_perc.append(c_peps_perc)\n",
    "\n",
    "    n_common_all = len(set(peps_org).intersection(set(c_peps_all)))\n",
    "    common_peps_perc_all.append(n_common_all / peps_org_n * 100)\n",
    "\n",
    "all_cluster_peps = pl.concat(\n",
    "    [all_cluster_peps, pl.DataFrame(common_peps_perc, all_cluster_peps_cols_x_perc)],\n",
    "    how=\"horizontal\",\n",
    ")\n",
    "\n",
    "# Prepare a table with common percentage between clusters\n",
    "common_peps_perc = (\n",
    "    all_cluster_peps.with_columns(\n",
    "        pl.col(all_cluster_peps_col_label)\n",
    "        .cast(pl.String)\n",
    "        .map_elements(lambda x: common_peps_perc_c_name(x), return_dtype=pl.String)\n",
    "    )\n",
    "    .select(pl.col(all_cluster_peps_col_label), pl.col(all_cluster_peps_cols_x_perc))\n",
    "    .rename(\n",
    "        {\n",
    "            all_cluster_peps_col_x_perc(ul): common_peps_perc_c_name(ul)\n",
    "            for ul in unique_labels\n",
    "        }\n",
    "    )\n",
    "    .to_pandas()\n",
    "    .set_index(all_cluster_peps_col_label)\n",
    ")\n",
    "common_peps_perc.index.name = \"\"\n",
    "\n",
    "# Prepare a table with common percentage for all clusters\n",
    "common_peps_perc_all = pl.DataFrame(\n",
    "    {\n",
    "        common_peps_perc_all_col_label: unique_labels,\n",
    "        common_peps_perc_all_col_perc: common_peps_perc_all,\n",
    "    }\n",
    ")\n",
    "common_peps_perc_all = common_peps_perc_all.with_columns(\n",
    "    pl.col(common_peps_perc_all_col_label)\n",
    "    .cast(pl.String)\n",
    "    .map_elements(lambda x: common_peps_perc_c_name(x), return_dtype=pl.String)\n",
    ")\n",
    "\n",
    "del all_cluster_peps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map original IDs to new ones to be changed later on\n",
    "# Taken from the previous section\n",
    "\n",
    "clust_id_map = {\n",
    "    \"C_7\": \"C_1\",\n",
    "    \"C_14\": \"C_2\",\n",
    "    \"C_5\": \"C_3\",\n",
    "    \"C_9\": \"C_4\",\n",
    "    \"C_1\": \"C_5\",\n",
    "    \"C_0\": \"C_6\",\n",
    "    \"C_6\": \"C_7\",\n",
    "    \"C_11\": \"C_8\",\n",
    "    \"C_3\": \"C_9\",\n",
    "    \"C_8\": \"C_10\",\n",
    "    \"C_13\": \"C_11\",\n",
    "    \"C_2\": \"C_12\",\n",
    "    \"C_10\": \"C_13\",\n",
    "    \"C_4\": \"C_14\",\n",
    "    \"C_12\": \"C_15\",\n",
    "}\n",
    "\n",
    "common_peps_perc = common_peps_perc.rename(columns=clust_id_map).rename(\n",
    "    index=clust_id_map\n",
    ")\n",
    "\n",
    "common_peps_perc_all = common_peps_perc_all.with_columns(\n",
    "    pl.col(common_peps_perc_all_col_label).replace(clust_id_map)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure config\n",
    "\n",
    "fig_size = figsize_in_mm(102.5, 60.6)\n",
    "\n",
    "fig_name = \"fig-3-clusters-peptides-all\"\n",
    "\n",
    "tick_label_fontsize = 5\n",
    "axis_label_fontsize = 5\n",
    "\n",
    "cbar_label_fontsize = 6\n",
    "cbar_tick_label_fontsize = 6\n",
    "\n",
    "cbar_pad = 0.02\n",
    "\n",
    "bar_width = 0.5\n",
    "block_height = bar_width\n",
    "\n",
    "y_gap_width = 0.1\n",
    "\n",
    "# cmap = plt.cm.inferno\n",
    "cmap = sns.cm.rocket\n",
    "\n",
    "color_100 = (0.5, 0.5, 0.5, 1)\n",
    "\n",
    "height_ratios = [1, 0.7]\n",
    "\n",
    "lower_tick_label_fontsize = 6\n",
    "lower_axis_label_fontsize = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce helper figure for the dendrogram sorting and tree\n",
    "\n",
    "cm = sns.clustermap(\n",
    "    common_peps_perc.T,\n",
    "    figsize=figsize_in_mm(115, 55),\n",
    "    xticklabels=True,\n",
    "    yticklabels=True,\n",
    "    row_cluster=False,\n",
    "    cbar=False,\n",
    ")\n",
    "\n",
    "cm.ax_row_dendrogram.set_visible(False)\n",
    "cm.ax_cbar.set_visible(False)\n",
    "\n",
    "file_name = figures_main_dir.joinpath(f\"{fig_name}-HELP.pdf\")\n",
    "cm.figure.savefig(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save figure\n",
    "\n",
    "fig = plt.figure(figsize=fig_size, layout=\"constrained\")\n",
    "\n",
    "gs = fig.add_gridspec(nrows=2, ncols=1, hspace=0, wspace=0, height_ratios=height_ratios)\n",
    "# axs = gs.subplots(sharex=\"all\")\n",
    "\n",
    "ax = fig.add_subplot(gs[0])\n",
    "\n",
    "# vmin = common_peps_perc.min().min()\n",
    "# vmax = common_peps_perc.replace(100.0, np.nan).max().max()\n",
    "# vmin = 0\n",
    "# vmax = 100\n",
    "vmin = min(\n",
    "    common_peps_perc.min().min(),\n",
    "    common_peps_perc_all[common_peps_perc_all_col_perc].min(),\n",
    ")\n",
    "vmax = max(\n",
    "    common_peps_perc.replace(100.0, np.nan).max().max(),\n",
    "    common_peps_perc_all[common_peps_perc_all_col_perc].max(),\n",
    ")\n",
    "\n",
    "norm = plt.matplotlib.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "sorted_cols = [t.get_text() for t in cm.ax_heatmap.xaxis.get_ticklabels()]\n",
    "\n",
    "pep_perc_sorted = common_peps_perc.loc[sorted_cols]\n",
    "\n",
    "y_labels = sorted_cols\n",
    "\n",
    "y_ticks = (\n",
    "    np.arange(0, pep_perc_sorted.shape[1]) * block_height\n",
    "    + np.arange(0, pep_perc_sorted.shape[1]) * y_gap_width\n",
    "    + block_height / 2\n",
    ")\n",
    "\n",
    "heights = np.full(pep_perc_sorted.shape[0], block_height)\n",
    "\n",
    "y = 0\n",
    "\n",
    "for c in y_labels:\n",
    "    colors = (\n",
    "        pep_perc_sorted.loc[:, c]\n",
    "        .map(lambda x: color_100 if x == 100.0 else cmap(norm(x)))\n",
    "        .to_list()\n",
    "    )\n",
    "\n",
    "    ax.bar(sorted_cols, heights, width=bar_width, bottom=y, color=colors)\n",
    "\n",
    "    y = y + block_height + y_gap_width\n",
    "\n",
    "ax.set_yticks(y_ticks, y_labels)\n",
    "\n",
    "_ = ax.set_ylabel(\"Clusters\", size=axis_label_fontsize)\n",
    "\n",
    "ax.tick_params(axis=\"y\", labelsize=tick_label_fontsize)\n",
    "\n",
    "ax.tick_params(bottom=False, labelbottom=False)\n",
    "\n",
    "ax_lower = fig.add_subplot(gs[1], sharex=ax)\n",
    "\n",
    "pep_perc_sorted = common_peps_perc_all.sort(\n",
    "    pl.col(common_peps_perc_all_col_label).cast(pl.Enum(sorted_cols))\n",
    ")\n",
    "\n",
    "colors = [cmap(norm(x)) for x in pep_perc_sorted[common_peps_perc_all_col_perc]]\n",
    "\n",
    "_ = ax_lower.bar(\n",
    "    pep_perc_sorted[common_peps_perc_all_col_label],\n",
    "    pep_perc_sorted[common_peps_perc_all_col_perc],\n",
    "    width=bar_width,\n",
    "    color=colors,\n",
    ")\n",
    "\n",
    "y_ticks_lower = [20, 40, 60, 80]\n",
    "ax_lower.set_yticks(y_ticks_lower, y_ticks_lower)\n",
    "\n",
    "ax_lower.yaxis.set_inverted(True)\n",
    "\n",
    "_ = ax_lower.set_ylabel(\"Common\\npeptides (%)\", size=lower_axis_label_fontsize)\n",
    "\n",
    "ax_lower.spines[[\"top\"]].set_visible(True)\n",
    "ax_lower.spines[[\"bottom\"]].set_visible(False)\n",
    "\n",
    "ax_lower.tick_params(bottom=False, pad=0)\n",
    "\n",
    "ax_lower.tick_params(axis=\"x\", labelsize=tick_label_fontsize, rotation=90)\n",
    "ax_lower.tick_params(\n",
    "    axis=\"y\", reset=True, labelsize=lower_tick_label_fontsize, right=False\n",
    ")\n",
    "\n",
    "ax.margins(x=0, y=0)\n",
    "ax_lower.margins(x=0, y=0)\n",
    "\n",
    "cbar = fig.colorbar(\n",
    "    plt.cm.ScalarMappable(norm=norm, cmap=cmap),\n",
    "    ax=[ax, ax_lower],\n",
    "    orientation=\"vertical\",\n",
    "    shrink=0.7,\n",
    "    pad=cbar_pad,\n",
    ")\n",
    "cbar.set_label(\"Common peptides (%)\", size=cbar_label_fontsize)\n",
    "cbar.ax.tick_params(axis=\"y\", labelsize=cbar_tick_label_fontsize)\n",
    "\n",
    "fig.get_layout_engine().set(w_pad=0, h_pad=0, hspace=0, wspace=0)\n",
    "\n",
    "file_name = figures_main_dir.joinpath(f\"{fig_name}.pdf\")\n",
    "fig.savefig(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplementary Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of AA Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which number of positions options to draw\n",
    "\n",
    "n_positions = [2, 3, 4, 5, 6, 7, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare necessary data\n",
    "\n",
    "# Gather statistics for amino acids combinations\n",
    "aa_perc_col = \"AA_perc\"\n",
    "\n",
    "aa_comb_perc = []\n",
    "\n",
    "for n_p in n_positions:\n",
    "    # Prepare the amino acids combinations table\n",
    "    aa_combinations = pl.read_csv(aa_combinations_file(n_p))\n",
    "    comb_num = (\n",
    "        aa_combinations.group_by(aa_combinations_col_pos, maintain_order=True)\n",
    "        .agg(pl.col(aa_combinations_col_aa))\n",
    "        .with_columns(pl.col(aa_combinations_col_aa).list.len())\n",
    "    )\n",
    "\n",
    "    max_comb_n = len(AMINO_ACIDS) ** n_p\n",
    "    comb_num = comb_num.with_columns(\n",
    "        (pl.col(aa_combinations_col_aa) / max_comb_n * 100).alias(aa_perc_col)\n",
    "    )\n",
    "\n",
    "    aa_comb_perc.append(comb_num)\n",
    "\n",
    "del aa_combinations, comb_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure config\n",
    "\n",
    "fig_size = figsize_in_mm(max_fig_width_double_col, max_max_fig_height)\n",
    "\n",
    "fig_name = \"supp-aa-combinations-percentage\"\n",
    "\n",
    "sort = True\n",
    "sort_low_to_high = True\n",
    "\n",
    "pos_ticks_labelsize = 4\n",
    "perc_ticks_labelsize = 5\n",
    "\n",
    "# c_29 = \"C3\"\n",
    "# c_9 = \"C1\"\n",
    "# c_2 = \"C2\"\n",
    "# c_r = \"C0\"\n",
    "c_29 = plt.cm.Set2(5)\n",
    "c_9 = plt.cm.Set2(1)\n",
    "c_2 = plt.cm.Set2(0)\n",
    "c_r = plt.cm.Set2(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.colormaps[\"Set2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save figure\n",
    "\n",
    "nrows = len(n_positions)\n",
    "ncols = 1\n",
    "\n",
    "fig = plt.figure(figsize=fig_size, layout=\"constrained\")\n",
    "\n",
    "gs = fig.add_gridspec(nrows=nrows, ncols=ncols)\n",
    "axs = gs.subplots()\n",
    "\n",
    "for n_p, aa_perc, ax in zip(n_positions, aa_comb_perc, axs.flatten()):\n",
    "    if sort:\n",
    "        if sort_low_to_high:\n",
    "            descending = [False, False]\n",
    "        else:\n",
    "            descending = [True, False]\n",
    "        aa_perc = aa_perc.sort(\n",
    "            aa_perc_col, aa_combinations_col_pos, descending=descending\n",
    "        )\n",
    "\n",
    "    x = np.arange(aa_perc.shape[0])\n",
    "\n",
    "    if n_p == 7:\n",
    "        tick_labels = []\n",
    "        for ac in aa_perc[aa_combinations_col_pos]:\n",
    "            ac_list = ac.split(aa_combinations_list_sep)\n",
    "            new_lab = \", \".join(ac_list[:3]) + \",\\n\" + \", \".join(ac_list[3:])\n",
    "            tick_labels.append(new_lab)\n",
    "    else:\n",
    "        tick_labels = [\n",
    "            ac.replace(aa_combinations_list_sep, \", \")\n",
    "            for ac in aa_perc[aa_combinations_col_pos]\n",
    "        ]\n",
    "\n",
    "    colors = []\n",
    "    for pc in aa_perc[aa_combinations_col_pos]:\n",
    "        pc_list = pc.split(aa_combinations_list_sep)\n",
    "        if \"9\" in pc_list:\n",
    "            if \"2\" in pc_list:\n",
    "                colors.append(c_29)\n",
    "            else:\n",
    "                colors.append(c_9)\n",
    "        elif \"2\" in pc_list:\n",
    "            colors.append(c_2)\n",
    "        else:\n",
    "            colors.append(c_r)\n",
    "\n",
    "    rects = ax.bar(x, aa_perc[aa_perc_col], tick_label=tick_labels, color=colors)\n",
    "\n",
    "    if n_p == 2:\n",
    "        ax.bar_label(\n",
    "            rects,\n",
    "            labels=aa_perc[aa_perc_col].to_list(),\n",
    "            fontsize=perc_ticks_labelsize,\n",
    "            label_type=\"center\",\n",
    "            rotation=90,\n",
    "        )\n",
    "\n",
    "    ax.grid(axis=\"y\")\n",
    "    if n_p == 8 or n_p == 2 or n_p == 1:\n",
    "        rotation = 0\n",
    "    else:\n",
    "        rotation = 90\n",
    "    ax.tick_params(axis=\"x\", labelsize=pos_ticks_labelsize, rotation=rotation)\n",
    "    ax.tick_params(axis=\"y\", labelsize=perc_ticks_labelsize)\n",
    "    ax.margins(x=0)\n",
    "    ax.spines[[\"right\", \"top\"]].set_visible(True)\n",
    "    if n_p == 8 or n_p == 7:\n",
    "        ax.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0), useMathText=True)\n",
    "        ax.figure.draw_without_rendering()  # This needs to be done cause `offset text` is only created when drawing...\n",
    "        t = ax.yaxis.get_offset_text().get_text()\n",
    "        ax.yaxis.get_offset_text().set_visible(False)\n",
    "        ax.annotate(\n",
    "            t,\n",
    "            xy=(0, 0.5),\n",
    "            xycoords=\"axes fraction\",\n",
    "            xytext=(-3, 0),\n",
    "            textcoords=\"offset fontsize\",\n",
    "            fontsize=perc_ticks_labelsize,\n",
    "            va=\"center\",\n",
    "            ha=\"right\",\n",
    "            fontstyle=\"italic\",\n",
    "            rotation=90,\n",
    "        )\n",
    "\n",
    "_ = fig.supxlabel(\"Positions in peptide sequence\")\n",
    "_ = fig.supylabel(\"Portion of all possible amino acid combinations (%)\")\n",
    "\n",
    "fig.get_layout_engine().set(w_pad=0, h_pad=0.02, hspace=0.03)\n",
    "\n",
    "file_name = figures_supp_dir.joinpath(f\"{fig_name}.pdf\")\n",
    "fig.savefig(file_name)\n",
    "\n",
    "file_name = figures_supp_dir.joinpath(f\"{fig_name}.png\")\n",
    "fig.savefig(file_name, dpi=600)\n",
    "\n",
    "file_name = figures_supp_dir.joinpath(f\"{fig_name}.tif\")\n",
    "fig.savefig(file_name, dpi=600, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "\n",
    "file_name = figures_supp_dir.joinpath(f\"{fig_name}.eps\")\n",
    "fig.savefig(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best AA Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which number of positions options to draw\n",
    "\n",
    "n_positions = [1, 2, 3, 4, 5, 6, 7, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare necessary data\n",
    "\n",
    "pep_perc_col = \"Peptides_perc\"\n",
    "\n",
    "pep_col = samples_col_peptides_9\n",
    "\n",
    "# Get unique peptides\n",
    "samples = pl.read_csv(samples_supp_file)\n",
    "samples = samples.with_columns(\n",
    "    pl.col(samples_list_cols).str.split(samples_list_sep).fill_null(list())\n",
    ")\n",
    "samples = samples.filter(pl.col(pep_col).list.len() != 0)\n",
    "peptides = []\n",
    "for pep_list in samples[pep_col]:\n",
    "    peptides.extend(pep_list)\n",
    "peptides = np.array(sorted(set(peptides)))\n",
    "del samples\n",
    "\n",
    "peptides_n = len(peptides)\n",
    "\n",
    "del peptides\n",
    "\n",
    "best_aa_combs = []\n",
    "\n",
    "for n_p in n_positions:\n",
    "    # Prepare the amino acids combinations table\n",
    "    aa_combinations = pl.read_csv(aa_combinations_file(n_p))\n",
    "    aa_combinations = aa_combinations.with_columns(\n",
    "        pl.col(aa_combinations_col_pep).str.split(aa_combinations_list_sep)\n",
    "    )\n",
    "\n",
    "    aa_combinations = aa_combinations.with_columns(\n",
    "        (pl.col(aa_combinations_col_pep).list.len() / peptides_n * 100).alias(\n",
    "            pep_perc_col\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Get the best amino acid combination for all unique positions\n",
    "    best_aac = (\n",
    "        aa_combinations.group_by(aa_combinations_col_pos)\n",
    "        .agg(pl.all().sort_by(pep_perc_col).last())\n",
    "        .select(pl.col([aa_combinations_col_pos, aa_combinations_col_aa, pep_perc_col]))\n",
    "    )\n",
    "    best_aac = best_aac.sort(aa_combinations_col_pos)\n",
    "    if n_p == 1:\n",
    "        best_aac = best_aac.with_columns(\n",
    "            pl.col(aa_combinations_col_pos).cast(pl.String)\n",
    "        )\n",
    "    best_aa_combs.append(best_aac)\n",
    "\n",
    "del aa_combinations, best_aac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure config\n",
    "\n",
    "fig_size = figsize_in_mm(max_fig_width_double_col, max_max_fig_height)\n",
    "\n",
    "fig_name = \"supp-best-aa-combinations\"\n",
    "\n",
    "sort = True\n",
    "sort_low_to_high = False\n",
    "\n",
    "pos_ticks_labelsize = 4\n",
    "perc_ticks_labelsize = 5\n",
    "\n",
    "aa_font_size = 4\n",
    "\n",
    "# c_29 = \"C3\"\n",
    "# c_9 = \"C1\"\n",
    "# c_2 = \"C2\"\n",
    "# c_r = \"C0\"\n",
    "c_29 = plt.cm.Set2(5)\n",
    "c_9 = plt.cm.Set2(1)\n",
    "c_2 = plt.cm.Set2(0)\n",
    "c_r = plt.cm.Set2(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save figure\n",
    "\n",
    "nrows = 1\n",
    "ncols = len(n_positions)\n",
    "\n",
    "width_ratios = [0.4, 0.75, 0.9, 1, 1, 1, 1, 0.4]\n",
    "\n",
    "fig = plt.figure(figsize=fig_size, layout=\"constrained\")\n",
    "\n",
    "gs = fig.add_gridspec(nrows=nrows, ncols=ncols, width_ratios=width_ratios)\n",
    "axs = gs.subplots()\n",
    "\n",
    "for n_p, aa_perc, ax in zip(n_positions, best_aa_combs, axs.flatten()):\n",
    "    if sort:\n",
    "        if sort_low_to_high:\n",
    "            descending = False\n",
    "        else:\n",
    "            descending = True\n",
    "        aa_perc = aa_perc.sort(pep_perc_col, descending=descending)\n",
    "\n",
    "    x = np.arange(aa_perc.shape[0])\n",
    "\n",
    "    if n_p == 7:\n",
    "        tick_labels = []\n",
    "        for ac in aa_perc[aa_combinations_col_pos]:\n",
    "            ac_list = ac.split(aa_combinations_list_sep)\n",
    "            # new_lab = \", \".join(ac_list[:3]) + \",\\n\" + \", \".join(ac_list[3:])\n",
    "            new_lab = \", \".join(ac_list[:2]) + \",\\n\" + \", \".join(ac_list[2:4]) + \",\\n\" + \", \".join(ac_list[4:])\n",
    "            tick_labels.append(new_lab)\n",
    "    else:\n",
    "        tick_labels = [\n",
    "            ac.replace(aa_combinations_list_sep, \", \")\n",
    "            for ac in aa_perc[aa_combinations_col_pos]\n",
    "        ]\n",
    "\n",
    "    colors = []\n",
    "    for pc in aa_perc[aa_combinations_col_pos]:\n",
    "        pc_list = pc.split(aa_combinations_list_sep)\n",
    "        if \"9\" in pc_list:\n",
    "            if \"2\" in pc_list:\n",
    "                colors.append(c_29)\n",
    "            else:\n",
    "                colors.append(c_9)\n",
    "        elif \"2\" in pc_list:\n",
    "            colors.append(c_2)\n",
    "        else:\n",
    "            colors.append(c_r)\n",
    "\n",
    "    rects = ax.barh(x, aa_perc[pep_perc_col], tick_label=tick_labels, color=colors)\n",
    "\n",
    "    # Add amino acids\n",
    "    if n_p == 8:\n",
    "        rotation = 90\n",
    "    else:\n",
    "        rotation = 0\n",
    "    for r, aa in zip(rects, aa_perc[aa_combinations_col_aa]):\n",
    "        aa_str = aa.replace(aa_combinations_list_sep, \", \")\n",
    "        _ = ax.annotate(\n",
    "            aa_str,\n",
    "            xy=(0, r.get_y() + r.get_height() / 2),\n",
    "            xytext=(0.5, 0),\n",
    "            textcoords=\"offset fontsize\",\n",
    "            ha=\"left\",\n",
    "            va=\"center\",\n",
    "            fontsize=aa_font_size,\n",
    "            rotation=rotation,color=\"0.25\",fontfamily=\"monospace\"\n",
    "        )\n",
    "\n",
    "    ax.grid(axis=\"x\")\n",
    "    if n_p == 8 or n_p == 2 or n_p == 7:\n",
    "        rotation = 90\n",
    "    else:\n",
    "        rotation = 0\n",
    "    ax.tick_params(axis=\"y\", labelsize=pos_ticks_labelsize, rotation=rotation)\n",
    "    if n_p == 8 or n_p == 2 or n_p == 7:\n",
    "        tlab = ax.get_yticklabels()\n",
    "        ax.set_yticklabels(tlab, va=\"center\")\n",
    "    ax.tick_params(axis=\"x\", labelsize=perc_ticks_labelsize)\n",
    "    ax.margins(y=0.0025)\n",
    "    ax.spines[[\"right\", \"top\"]].set_visible(True)\n",
    "\n",
    "    # Change scientific notation\n",
    "    if n_p == 8:\n",
    "        ax.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0, 0), useMathText=True)\n",
    "        ax.figure.draw_without_rendering()  # This needs to be done cause `offset text` is only created when drawing...\n",
    "        t = ax.xaxis.get_offset_text().get_text()\n",
    "        ax.xaxis.get_offset_text().set_visible(False)\n",
    "        ax.annotate(\n",
    "            t,\n",
    "            xy=(0.5, 0),\n",
    "            xycoords=\"axes fraction\",\n",
    "            xytext=(0, -3),\n",
    "            textcoords=\"offset fontsize\",\n",
    "            fontsize=perc_ticks_labelsize,\n",
    "            va=\"top\",\n",
    "            ha=\"center\",\n",
    "            fontstyle=\"italic\",\n",
    "        )\n",
    "\n",
    "_ = fig.supylabel(\"Positions in peptide sequence\")\n",
    "_ = fig.supxlabel(\"Peptide coverage (%)\", y=0)\n",
    "\n",
    "fig.get_layout_engine().set(w_pad=0.02, h_pad=0.02, wspace=0.03)\n",
    "\n",
    "file_name = figures_supp_dir.joinpath(f\"{fig_name}.pdf\")\n",
    "fig.savefig(file_name)\n",
    "\n",
    "file_name = figures_supp_dir.joinpath(f\"{fig_name}.png\")\n",
    "fig.savefig(file_name, dpi=600)\n",
    "\n",
    "file_name = figures_supp_dir.joinpath(f\"{fig_name}.tif\")\n",
    "fig.savefig(file_name, dpi=600, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "\n",
    "file_name = figures_supp_dir.joinpath(f\"{fig_name}.eps\")\n",
    "fig.savefig(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AA Combination Frequency (all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might take a while to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the number of positions option to draw\n",
    "\n",
    "n_positions = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "# Select cut-off threshold for annotating the cumulative percent of peptides coverage\n",
    "\n",
    "sum_margin = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare necessary data\n",
    "\n",
    "pep_perc_col = \"Peptides_perc\"\n",
    "\n",
    "pep_col = samples_col_peptides_9\n",
    "\n",
    "pep_len = peptide_len\n",
    "\n",
    "blank_char = \"_\"\n",
    "\n",
    "first_pos_n = 1\n",
    "\n",
    "# Get unique peptides\n",
    "samples = pl.read_csv(samples_supp_file)\n",
    "samples = samples.with_columns(\n",
    "    pl.col(samples_list_cols).str.split(samples_list_sep).fill_null(list())\n",
    ")\n",
    "samples = samples.filter(pl.col(pep_col).list.len() != 0)\n",
    "peptides = []\n",
    "for pep_list in samples[pep_col]:\n",
    "    peptides.extend(pep_list)\n",
    "peptides = np.array(sorted(set(peptides)))\n",
    "del samples\n",
    "\n",
    "peptides_n = len(peptides)\n",
    "\n",
    "aa_combinations_all = []\n",
    "peptide_coverage_all = []\n",
    "above_margin_idx_all = []\n",
    "below_margin_comb_perc_all = []\n",
    "comb_peps_pssm_all = []\n",
    "comb_n_all = []\n",
    "\n",
    "for n_p in tqdm(n_positions):\n",
    "    # Prepare the amino acids combinations table\n",
    "    aa_combinations = pl.read_csv(aa_combinations_file(n_p))\n",
    "    aa_combinations = aa_combinations.with_columns(\n",
    "        pl.col(aa_combinations_col_pep).str.split(aa_combinations_list_sep)\n",
    "    )\n",
    "\n",
    "    if n_p == 1:\n",
    "        aa_combinations = aa_combinations.with_columns(\n",
    "            pl.col(aa_combinations_col_pos).cast(pl.List(int)),\n",
    "            pl.col(aa_combinations_col_aa).str.split(\";\"),\n",
    "        )\n",
    "    else:\n",
    "        aa_combinations = aa_combinations.with_columns(\n",
    "            pl.col(aa_combinations_col_pos).str.split(\";\").cast(pl.List(int)),\n",
    "            pl.col(aa_combinations_col_aa).str.split(\";\"),\n",
    "        )\n",
    "\n",
    "    aa_combinations = aa_combinations.with_columns(\n",
    "        (pl.col(aa_combinations_col_pep).list.len() / peptides_n * 100).alias(\n",
    "            pep_perc_col\n",
    "        )\n",
    "    )\n",
    "    aa_combinations = aa_combinations.sort(pep_perc_col, descending=True)\n",
    "\n",
    "    aa_combinations_all.append(aa_combinations)\n",
    "\n",
    "    comb_n = aa_combinations.shape[0]\n",
    "\n",
    "    comb_n_all.append(comb_n)\n",
    "\n",
    "    # Get the cumulative percent of peptides coverage\n",
    "    peptide_coverage = []\n",
    "    pep_c = set()\n",
    "    for pep_list in aa_combinations[aa_combinations_col_pep]:\n",
    "        pep_c.update(pep_list)\n",
    "        p_perc = len(pep_c) / peptides_n * 100\n",
    "        if p_perc >= 100:\n",
    "            n_left = aa_combinations.shape[0] - len(peptide_coverage)\n",
    "            peptide_coverage.extend([100.0] * n_left)\n",
    "            break\n",
    "        peptide_coverage.append(p_perc)\n",
    "    peptide_coverage = np.array(peptide_coverage)\n",
    "\n",
    "    peptide_coverage_all.append(peptide_coverage)\n",
    "\n",
    "    # Check the above threshold index\n",
    "    above_margin_idx = np.where(peptide_coverage >= sum_margin)[0][0]\n",
    "    # margin_diff = peptide_coverage[above_margin_idx] - sum_margin\n",
    "    # prev_diff = peptide_coverage[above_margin_idx] - peptide_coverage[above_margin_idx - 1]\n",
    "    # margin_val = above_margin_idx - margin_diff / prev_diff\n",
    "\n",
    "    above_margin_idx_all.append(above_margin_idx)\n",
    "\n",
    "    below_margin_comb_perc = (above_margin_idx + 1) / comb_n * 100\n",
    "\n",
    "    below_margin_comb_perc_all.append(below_margin_comb_perc)\n",
    "\n",
    "    # Make \"fake\" peptides from amino acids combinations below threshold only\n",
    "    blank_pep = np.array([blank_char] * pep_len)\n",
    "\n",
    "    below_margin_aa_combs = aa_combinations.slice(0, above_margin_idx + 1)\n",
    "\n",
    "    comb_peps = []\n",
    "    for i in range(below_margin_aa_combs.shape[0]):\n",
    "        row = below_margin_aa_combs.row(i)\n",
    "        new_pep = blank_pep.copy()\n",
    "        new_pep[np.array(row[0]) - first_pos_n] = row[1]\n",
    "        comb_peps.append(\"\".join(new_pep))\n",
    "\n",
    "    # Create a PSSM table out of those peptides\n",
    "    comb_peps_pssm = info_pssm(comb_peps, alphabet=AMINO_ACIDS + [blank_char])\n",
    "    aa_cols = comb_peps_pssm.columns.to_list()\n",
    "    aa_cols.remove(blank_char)\n",
    "    comb_peps_pssm = comb_peps_pssm.loc[:, aa_cols]\n",
    "\n",
    "    comb_peps_pssm_all.append(comb_peps_pssm)\n",
    "\n",
    "del aa_combinations, peptide_coverage, comb_peps_pssm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure config\n",
    "\n",
    "fig_size = figsize_in_mm(max_fig_width_double_col, max_max_fig_height)\n",
    "\n",
    "fig_name = \"supp-aa-combinations-coverage-all\"\n",
    "\n",
    "marker_size = 4\n",
    "\n",
    "pos_n_label_pos = (0.9, 0.8)\n",
    "pos_n_label_color = \"black\"\n",
    "pos_n_label_fontsize = 7\n",
    "\n",
    "best_combs_n = 4\n",
    "best_combs_pos = (0.36, 0.85)\n",
    "best_combs_fontsize = 6\n",
    "best_combs_color = \"black\"\n",
    "\n",
    "logo_x = 0.8\n",
    "logo_size = (70 / 72 * logo_x, 50 / 72 * logo_x)  # Pixels\n",
    "logo_location = (0.81, 0.6)\n",
    "logo_font_size = 5\n",
    "\n",
    "sum_annot_color = \"black\"\n",
    "sum_annot_linewidth = 1.25\n",
    "sum_annot_font_size = 6\n",
    "sum_annot_arrow_x_offset = 0.003125  # This is in % of data points\n",
    "sum_annot_arrow_lenth = 15\n",
    "sum_annot_arrowprops = dict(\n",
    "    facecolor=sum_annot_color, headwidth=4, headlength=4, width=0.5\n",
    ")\n",
    "sum_annot_arrow_pos_pep = 0.77\n",
    "sum_annot_arrow_pos_comb = 0.5\n",
    "\n",
    "ax2_linewidth = 1.8\n",
    "ax2_color = \"0.4\"\n",
    "ax2_label_x_stretch = 0.98  # the smaller the number, the greater the stretch\n",
    "\n",
    "comb_n_x_fontsize = 6\n",
    "sci_not_pos = (0.4, -1.1)\n",
    "\n",
    "axes_x_margin = 0.01\n",
    "\n",
    "downsample_save_first_n = 1_000\n",
    "downsample_output_n = 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save figure\n",
    "\n",
    "temp_sep = \";\"\n",
    "\n",
    "nrows = len(n_positions)\n",
    "ncols = 1\n",
    "\n",
    "fig = plt.figure(figsize=fig_size, layout=\"constrained\")\n",
    "\n",
    "gs = fig.add_gridspec(nrows=nrows, ncols=ncols)\n",
    "axs = gs.subplots()\n",
    "\n",
    "for (\n",
    "    n_p,\n",
    "    aa_combinations,\n",
    "    peptide_coverage,\n",
    "    above_margin_idx,\n",
    "    below_margin_comb_perc,\n",
    "    comb_peps_pssm,\n",
    "    comb_n,\n",
    "    ax,\n",
    ") in tzip(\n",
    "    n_positions,\n",
    "    aa_combinations_all,\n",
    "    peptide_coverage_all,\n",
    "    above_margin_idx_all,\n",
    "    below_margin_comb_perc_all,\n",
    "    comb_peps_pssm_all,\n",
    "    comb_n_all,\n",
    "    axs.flatten(),\n",
    "):\n",
    "    x = np.arange(comb_n)\n",
    "\n",
    "    # Make each indices combination have its own color\n",
    "    unique_pos = aa_combinations[aa_combinations_col_pos].unique(maintain_order=True)\n",
    "    unique_pos_n = len(unique_pos)\n",
    "    colors = color_pallet(unique_pos_n)\n",
    "\n",
    "    # Downsampling points (but leaving first N)\n",
    "    if n_p > 1:\n",
    "        rest_n = comb_n - downsample_save_first_n\n",
    "        downsample_every_n = max(1, int(rest_n / downsample_output_n))\n",
    "        downsample_cycle_values = itertools.cycle(\n",
    "            [False] * (downsample_every_n - 1) + [True]\n",
    "        )\n",
    "        downsample_mask = list(itertools.islice(downsample_cycle_values, rest_n))\n",
    "        downsample_mask = [True] * downsample_save_first_n + downsample_mask\n",
    "        downsample_mask[-1] = True\n",
    "        x = x[downsample_mask]\n",
    "        aa_combinations = aa_combinations.filter(downsample_mask)\n",
    "\n",
    "    # Map all positions to colors\n",
    "    comb_colors = (\n",
    "        aa_combinations[aa_combinations_col_pos]\n",
    "        .cast(pl.List(pl.String))\n",
    "        .list.join(temp_sep)\n",
    "    )\n",
    "    comb_colors = (\n",
    "        comb_colors.replace(\n",
    "            old=unique_pos.cast(pl.List(pl.String)).list.join(temp_sep),\n",
    "            new=pl.Series(colors).cast(pl.List(pl.String)).list.join(temp_sep),\n",
    "        )\n",
    "        .str.split(temp_sep)\n",
    "        .cast(pl.List(pl.Float64))\n",
    "        .to_list()\n",
    "    )\n",
    "\n",
    "    _ = ax.scatter(x, aa_combinations[pep_perc_col], s=marker_size, c=comb_colors)\n",
    "\n",
    "    # Cumulative frequency of occurrence\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "\n",
    "    ax2.spines[\"right\"].set_visible(True)\n",
    "    ax2.spines[\"right\"].set_color(ax2_color)\n",
    "    ax2.tick_params(axis=\"y\", colors=ax2_color)\n",
    "\n",
    "    _ = ax2.plot(peptide_coverage, color=ax2_color, linewidth=ax2_linewidth)\n",
    "\n",
    "    # X% peptide sum annotations\n",
    "\n",
    "    _ = ax2.axvline(\n",
    "        above_margin_idx, color=sum_annot_color, linewidth=sum_annot_linewidth\n",
    "    )\n",
    "\n",
    "    ybound = ax.get_ybound()\n",
    "\n",
    "    arrow_offset = sum_annot_arrow_x_offset * comb_n\n",
    "\n",
    "    _ = ax.annotate(\n",
    "        f\"{sum_margin}% of peptides\",\n",
    "        xy=(\n",
    "            above_margin_idx + arrow_offset,\n",
    "            ybound[0] + (ybound[1] - ybound[0]) * sum_annot_arrow_pos_pep,\n",
    "        ),\n",
    "        xytext=(sum_annot_arrow_lenth, 0),\n",
    "        textcoords=\"offset points\",\n",
    "        ha=\"left\",\n",
    "        va=\"center\",\n",
    "        fontsize=sum_annot_font_size,\n",
    "        color=sum_annot_color,\n",
    "        arrowprops=sum_annot_arrowprops,\n",
    "    )\n",
    "\n",
    "    _ = ax.annotate(\n",
    "        f\"{below_margin_comb_perc:.2f}% of combinations\\n(\"\n",
    "        + r\"$\\bf{\"\n",
    "        + f\"{above_margin_idx+1:,}\"\n",
    "        + \"}$)\",\n",
    "        xy=(\n",
    "            above_margin_idx + arrow_offset,\n",
    "            ybound[0] + (ybound[1] - ybound[0]) * sum_annot_arrow_pos_comb,\n",
    "        ),\n",
    "        xytext=(sum_annot_arrow_lenth, 0),\n",
    "        textcoords=\"offset points\",\n",
    "        ha=\"left\",\n",
    "        va=\"center\",\n",
    "        fontsize=sum_annot_font_size,\n",
    "        color=sum_annot_color,\n",
    "        arrowprops=sum_annot_arrowprops,\n",
    "    )\n",
    "\n",
    "    ax.margins(x=axes_x_margin)\n",
    "    ax2.margins(x=axes_x_margin)\n",
    "\n",
    "    # Motif logo\n",
    "\n",
    "    trans = fig.dpi_scale_trans + ScaledTranslation(\n",
    "        logo_location[0], logo_location[1], ax.transAxes\n",
    "    )\n",
    "    motif_ax = inset_axes(\n",
    "        ax,\n",
    "        width=\"100%\",\n",
    "        height=\"100%\",\n",
    "        bbox_to_anchor=(\n",
    "            -logo_size[0] / 2,\n",
    "            -logo_size[1] / 2,\n",
    "            logo_size[0],\n",
    "            logo_size[1],\n",
    "        ),\n",
    "        bbox_transform=trans,\n",
    "        borderpad=0,\n",
    "        axes_kwargs={\"anchor\": \"C\"},\n",
    "        loc=\"center\",\n",
    "    )\n",
    "\n",
    "    motif_ax.spines[[\"right\", \"top\"]].set_visible(True)\n",
    "\n",
    "    # Create a motif from amino acids combinations below threshold only\n",
    "    logo = logomaker.Logo(\n",
    "        comb_peps_pssm,\n",
    "        color_scheme=\"weblogo_protein\",\n",
    "        stack_order=\"big_on_top\",\n",
    "        flip_below=False,\n",
    "        center_values=False,\n",
    "        baseline_width=0,\n",
    "        vpad=0.05,\n",
    "        ax=motif_ax,\n",
    "    )\n",
    "\n",
    "    logo.ax.set_xticks(\n",
    "        range(0, pep_len), labels=[str(i) for i in range(1, pep_len + 1)]\n",
    "    )\n",
    "    logo.ax.xaxis.set_tick_params(length=0)\n",
    "    _ = logo.ax.set_ylabel(\"Bits\", size=logo_font_size, labelpad=0)\n",
    "    logo.ax.tick_params(axis=\"both\", labelsize=logo_font_size)\n",
    "\n",
    "    # Add number of positions label\n",
    "    label = f\"{n_p} position\"\n",
    "    if n_p > 1:\n",
    "        label += \"s\"\n",
    "    _ = ax.text(\n",
    "        pos_n_label_pos[0],\n",
    "        pos_n_label_pos[1],\n",
    "        label,\n",
    "        transform=ax.transAxes,\n",
    "        ha=\"left\",\n",
    "        va=\"top\",\n",
    "        color=pos_n_label_color,\n",
    "        size=pos_n_label_fontsize,\n",
    "    )\n",
    "\n",
    "    # Add best combinations\n",
    "    best_combs = []\n",
    "    for row in aa_combinations.slice(0, best_combs_n).iter_rows():\n",
    "        combs = [f\"{p}({aa})\" for p, aa in zip(row[0], row[1])]\n",
    "        combs = \", \".join(combs)\n",
    "        combs = \"  \" + combs\n",
    "        best_combs.append(combs)\n",
    "    best_combs = \"\\n\".join(best_combs)\n",
    "    best_combs_str = f\"Best {best_combs_n} combinations:\\n{best_combs}\"\n",
    "    _ = ax.text(\n",
    "        best_combs_pos[0],\n",
    "        best_combs_pos[1],\n",
    "        best_combs_str,\n",
    "        transform=ax.transAxes,\n",
    "        ha=\"left\",\n",
    "        va=\"top\",\n",
    "        color=best_combs_color,\n",
    "        size=best_combs_fontsize,\n",
    "    )\n",
    "\n",
    "    ax.spines[[\"top\"]].set_visible(True)\n",
    "\n",
    "    if n_p == 2 or n_p == 3:\n",
    "        ax.xaxis.set_major_formatter(lambda x, _: f\"{int(x):,}\")\n",
    "\n",
    "    # Change scientific notation\n",
    "    if n_p == 4 or n_p == 5 or n_p == 6 or n_p == 7 or n_p == 8:\n",
    "        ax.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0, 0), useMathText=True)\n",
    "        ax.figure.draw_without_rendering()  # This needs to be done cause `offset text` is only created when drawing...\n",
    "        t = ax.xaxis.get_offset_text().get_text()\n",
    "        ax.xaxis.get_offset_text().set_visible(False)\n",
    "        ax.annotate(\n",
    "            t,\n",
    "            xy=(1, 0),\n",
    "            xycoords=\"axes fraction\",\n",
    "            xytext=sci_not_pos,\n",
    "            textcoords=\"offset fontsize\",\n",
    "            fontsize=comb_n_x_fontsize,\n",
    "            va=\"top\",\n",
    "            ha=\"left\",\n",
    "            fontstyle=\"italic\",\n",
    "        )\n",
    "\n",
    "_ = fig.supxlabel(\"Amino acids and positions combination\")\n",
    "_ = fig.supylabel(\"Peptide coverage (%)\")\n",
    "_ = fig.text(\n",
    "    1,\n",
    "    0.5,\n",
    "    \"Cumulative peptide coverage (%)\",\n",
    "    color=ax2_color,\n",
    "    rotation=90,\n",
    "    ha=\"center\",\n",
    "    va=\"bottom\",\n",
    "    rotation_mode=\"anchor\",\n",
    ")\n",
    "\n",
    "fig.get_layout_engine().set(\n",
    "    w_pad=0.02, h_pad=0.02, hspace=0.03, rect=(0, 0, ax2_label_x_stretch, 1)\n",
    ")\n",
    "\n",
    "file_name = figures_supp_dir.joinpath(f\"{fig_name}.pdf\")\n",
    "fig.savefig(file_name)\n",
    "\n",
    "file_name = figures_supp_dir.joinpath(f\"{fig_name}.png\")\n",
    "fig.savefig(file_name, dpi=600)\n",
    "\n",
    "file_name = figures_supp_dir.joinpath(f\"{fig_name}.tif\")\n",
    "fig.savefig(file_name, dpi=600, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "\n",
    "file_name = figures_supp_dir.joinpath(f\"{fig_name}.eps\")\n",
    "fig.savefig(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populations Frequencies Bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which samples file to use\n",
    "\n",
    "# Main\n",
    "samples = pl.read_csv(samples_main_file)\n",
    "\n",
    "# Supplementary\n",
    "# samples = pl.read_csv(samples_supp_file)\n",
    "\n",
    "# Select which frequency data to use\n",
    "\n",
    "# samples_cols_freqs = samples_cols_freqs_a  # Only A* alleles\n",
    "# freqs_pop_desc_cols_alleles = [freqs_pop_desc_col_a_b_drb1]\n",
    "\n",
    "# samples_cols_freqs = samples_cols_freqs_b  # Only B* alleles\n",
    "# freqs_pop_desc_cols_alleles = [freqs_pop_desc_col_a_b_drb1]\n",
    "\n",
    "# samples_cols_freqs = samples_cols_freqs_c  # Only C* alleles\n",
    "# freqs_pop_desc_cols_alleles = [freqs_pop_desc_col_c]\n",
    "\n",
    "# samples_cols_freqs = samples_cols_freqs_abc_any  # A+B+C union\n",
    "samples_cols_freqs = samples_cols_freqs_abc_all  # A+B+C intersection\n",
    "freqs_pop_desc_cols_alleles = [freqs_pop_desc_col_a_b_drb1, freqs_pop_desc_col_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "\n",
    "pop_samples_n_col = \"Samples_number\"\n",
    "\n",
    "# Samples frequencies data\n",
    "\n",
    "freqs = samples[samples_cols_freqs]\n",
    "\n",
    "del samples\n",
    "\n",
    "new_cols = {c: c.split(\"_\")[1] for c in freqs.columns}\n",
    "freqs = freqs.rename(new_cols)\n",
    "\n",
    "freqs = freqs.filter(pl.all_horizontal(pl.col(\"*\").is_not_null()))\n",
    "\n",
    "# Change the ordering based on clustering\n",
    "pop_order = cos_sim_clustermap_order(freqs)\n",
    "freqs = freqs.select(pl.col(pop_order))\n",
    "\n",
    "# Original database populations samples numbers\n",
    "\n",
    "freqs_pop_desc = pl.read_csv(freqs_pop_desc_file)\n",
    "\n",
    "freqs_pop_desc_samples_n = freqs_pop_desc.select(\n",
    "    pl.col(freqs_pop_desc_col_pop_code),\n",
    "    pl.sum_horizontal(pl.col(freqs_pop_desc_cols_alleles)).alias(pop_samples_n_col),\n",
    ")\n",
    "\n",
    "freqs_pop_desc_samples_n = freqs_pop_desc_samples_n.select(\n",
    "    pl.col(pop_samples_n_col)\n",
    ").transpose(column_names=freqs_pop_desc_samples_n[freqs_pop_desc_col_pop_code])\n",
    "\n",
    "del freqs_pop_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure config\n",
    "\n",
    "fig_size = figsize_in_mm(max_fig_width_double_col, max_max_fig_height * 0.45)\n",
    "\n",
    "fig_name = \"supp-pop-freqs\"\n",
    "\n",
    "bar_width = 30\n",
    "bar_color = plt.cm.Set2(2)\n",
    "\n",
    "freq_threshold = 0.05\n",
    "# freq_threshold_color = \"C3\"\n",
    "# freq_threshold_color = plt.cm.Set2(1)\n",
    "# freq_threshold_color = plt.cm.Set2(5)\n",
    "freq_threshold_color = plt.cm.Set2(7)\n",
    "freq_threshold_linewidth = 1\n",
    "\n",
    "gs_grid = (5, 5)  # (nrows, ncols); there are 21 populations\n",
    "\n",
    "pop_label_size = 6\n",
    "pop_label_x = 0.95\n",
    "pop_label_y = 0.9\n",
    "pop_label_color = \"black\"\n",
    "pop_label_kwargs = dict(\n",
    "    ha=\"right\", va=\"top\", color=pop_label_color, size=pop_label_size\n",
    ")\n",
    "\n",
    "x_label_hori_i = 0\n",
    "y_label_vert_i = 2\n",
    "\n",
    "axes_x_margin = 0.03\n",
    "\n",
    "extra_axis_size = (0.27, 0.15)  # (width, height)\n",
    "extra_axis_y = 0.094\n",
    "extra_axis_fontsize = 5\n",
    "\n",
    "above_thrsh_axis_loc = (0.35, extra_axis_y)  # (left, bottom)\n",
    "\n",
    "freq_samples_axis_loc = (0.728, extra_axis_y)  # (left, bottom)\n",
    "\n",
    "fig_canvas_rect = (-0.013, 0.07, 1.013, 1.029)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save figure\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", category=UserWarning, message=\"This figure includes Axes\"\n",
    ")\n",
    "\n",
    "populations = freqs.columns\n",
    "\n",
    "fig = plt.figure(figsize=fig_size, layout=\"tight\")\n",
    "\n",
    "gs = fig.add_gridspec(nrows=gs_grid[0], ncols=gs_grid[1], hspace=0, wspace=0)\n",
    "axs = gs.subplots(sharex=\"all\", sharey=\"all\")\n",
    "\n",
    "# Main panels\n",
    "\n",
    "x = np.arange(freqs.shape[0])\n",
    "\n",
    "for ax, pop in zip(axs.flatten(), populations):\n",
    "    ax.spines[[\"right\", \"top\"]].set_visible(True)\n",
    "    ax.set_xticks([])\n",
    "    # ax.set_yticks([])\n",
    "\n",
    "    pop_freqs = freqs[pop].to_numpy()\n",
    "\n",
    "    _ = ax.bar(x, pop_freqs, width=bar_width, color=bar_color)\n",
    "    # _ = ax.stem(x, pop_freqs, linefmt=\"C0-\", basefmt=\"None\", markerfmt=\"None\")\n",
    "\n",
    "    ax.axhline(\n",
    "        freq_threshold, color=freq_threshold_color, linewidth=freq_threshold_linewidth\n",
    "    )\n",
    "\n",
    "    ax.text(pop_label_x, pop_label_y, pop, transform=ax.transAxes, **pop_label_kwargs)\n",
    "\n",
    "y_ticks = axs.flatten()[0].get_yticks().tolist()\n",
    "y_ticks.remove(0)\n",
    "y_ticks.remove(0.2)\n",
    "y_ticks.append(freq_threshold)\n",
    "y_ticks = sorted(y_ticks)\n",
    "axs.flatten()[0].set_yticks(y_ticks)\n",
    "\n",
    "y_top = axs.flatten()[0].get_ylim()[1]\n",
    "for ax in axs.flatten():\n",
    "    # ax.set_ylim(0, y_top)\n",
    "    ax.margins(x=axes_x_margin)\n",
    "\n",
    "axs[-1][x_label_hori_i].set_xlabel(\"Sample\")\n",
    "axs[y_label_vert_i][0].set_ylabel(\"Frequency\")\n",
    "\n",
    "for ax in axs.flatten()[[1, 2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 16, 17, 18, 19]]:\n",
    "    ax.tick_params(axis=\"y\", left=False)\n",
    "    # ax.set_yticks([])\n",
    "\n",
    "# Automatically delete last unused axes\n",
    "n_ax_to_del = gs_grid[0] * gs_grid[1] - len(populations)\n",
    "if n_ax_to_del != 0:\n",
    "    for ax in axs.flatten()[-n_ax_to_del:]:\n",
    "        ax.set_axis_off()\n",
    "\n",
    "axs.flatten()[0].annotate(\n",
    "    \"a\",\n",
    "    xy=(0, 1),\n",
    "    xycoords=\"axes fraction\",\n",
    "    xytext=(-2.7, 0),\n",
    "    textcoords=\"offset fontsize\",\n",
    "    **label_kwargs,\n",
    ")\n",
    "\n",
    "# Samples above threshold\n",
    "\n",
    "ax = fig.add_axes(\n",
    "    (\n",
    "        above_thrsh_axis_loc[0],\n",
    "        above_thrsh_axis_loc[1],\n",
    "        extra_axis_size[0],\n",
    "        extra_axis_size[1],\n",
    "    )\n",
    ")\n",
    "\n",
    "pops_col = \"Population\"\n",
    "at_col = \"Samples\"\n",
    "\n",
    "above_thrsh_samples = (freqs >= freq_threshold).sum()\n",
    "above_thrsh_samples = above_thrsh_samples.transpose(\n",
    "    include_header=True, header_name=pops_col, column_names=[at_col]\n",
    ")\n",
    "above_thrsh_samples = above_thrsh_samples.sort(\n",
    "    [at_col, pops_col], descending=[True, False]\n",
    ")\n",
    "\n",
    "x = np.arange(above_thrsh_samples.shape[0])\n",
    "\n",
    "at_order_pop = above_thrsh_samples[pops_col].to_list()\n",
    "\n",
    "_ = ax.bar(x, above_thrsh_samples[at_col], color=bar_color, tick_label=at_order_pop)\n",
    "\n",
    "ax.margins(x=axes_x_margin / 2)\n",
    "\n",
    "ax.tick_params(axis=\"x\", labelsize=extra_axis_fontsize, rotation=90)\n",
    "ax.tick_params(axis=\"y\", labelsize=extra_axis_fontsize)\n",
    "ax.set_ylabel(\"No. of samples\", fontsize=extra_axis_fontsize)\n",
    "\n",
    "ax.annotate(\n",
    "    \"b\",\n",
    "    xy=(0, 1),\n",
    "    xycoords=\"axes fraction\",\n",
    "    xytext=(-3, 0),\n",
    "    textcoords=\"offset fontsize\",\n",
    "    **label_kwargs,\n",
    ")\n",
    "\n",
    "# Number of samples from the original database\n",
    "\n",
    "ax = fig.add_axes(\n",
    "    (\n",
    "        freq_samples_axis_loc[0],\n",
    "        freq_samples_axis_loc[1],\n",
    "        extra_axis_size[0],\n",
    "        extra_axis_size[1],\n",
    "    )\n",
    ")\n",
    "\n",
    "freqs_pop_desc_samples_n_sorted = freqs_pop_desc_samples_n.select(pl.col(at_order_pop))\n",
    "\n",
    "_ = ax.bar(\n",
    "    x,\n",
    "    freqs_pop_desc_samples_n_sorted.row(0),\n",
    "    color=bar_color,\n",
    "    tick_label=freqs_pop_desc_samples_n_sorted.columns,\n",
    ")\n",
    "\n",
    "ax.margins(x=axes_x_margin / 2)\n",
    "\n",
    "ax.tick_params(axis=\"x\", labelsize=extra_axis_fontsize, rotation=90)\n",
    "ax.tick_params(axis=\"y\", labelsize=extra_axis_fontsize)\n",
    "ax.set_ylabel(\"No. of samples\", fontsize=extra_axis_fontsize)\n",
    "\n",
    "ax.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0), useMathText=True)\n",
    "ax.figure.draw_without_rendering()  # This needs to be done cause `offset text` is only created when drawing...\n",
    "t = ax.yaxis.get_offset_text().get_text()\n",
    "ax.yaxis.get_offset_text().set_visible(False)\n",
    "ax.annotate(\n",
    "    t,\n",
    "    xy=(0, 1),\n",
    "    xycoords=\"axes fraction\",\n",
    "    xytext=(0, 0),\n",
    "    textcoords=\"offset fontsize\",\n",
    "    fontsize=extra_axis_fontsize,\n",
    "    va=\"bottom\",\n",
    "    ha=\"left\",\n",
    "    fontstyle=\"italic\",\n",
    ")\n",
    "\n",
    "ax.annotate(\n",
    "    \"c\",\n",
    "    xy=(0, 1),\n",
    "    xycoords=\"axes fraction\",\n",
    "    xytext=(-2.8, 0),\n",
    "    textcoords=\"offset fontsize\",\n",
    "    **label_kwargs,\n",
    ")\n",
    "\n",
    "fig.get_layout_engine().set(w_pad=0, h_pad=0, rect=fig_canvas_rect)\n",
    "\n",
    "file_name = figures_supp_dir.joinpath(f\"{fig_name}.pdf\")\n",
    "fig.savefig(file_name)\n",
    "\n",
    "file_name = figures_supp_dir.joinpath(f\"{fig_name}.png\")\n",
    "fig.savefig(file_name, dpi=600)\n",
    "\n",
    "file_name = figures_supp_dir.joinpath(f\"{fig_name}.tif\")\n",
    "fig.savefig(file_name, dpi=600, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "\n",
    "file_name = figures_supp_dir.joinpath(f\"{fig_name}.eps\")\n",
    "fig.savefig(file_name)\n",
    "\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to clean up and delete all additional files and directories created throughout the analysis.\n",
    "\n",
    "**Do not run the second cell unless you want to end your work here or start over.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a safety code\n",
    "\n",
    "raise KeyboardInterrupt(\"Are you sure you want to run the cell below?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to do a clean-up\n",
    "\n",
    "shutil.rmtree(data_subs_dir)\n",
    "shutil.rmtree(figures_gen_dir)\n",
    "shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join([f\"{f}\" for f in ext_data_files]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carmen-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
